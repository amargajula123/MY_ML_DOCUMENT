{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eb078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Agenda :=\n",
    "    1. SVM Kernal -->practicals\n",
    "    2. Bagging & Boosting --> Random Forest , Adaboost\n",
    "    3. Pick up any Problem Statement.\n",
    "    4. ROC and AUC curv ----> the part of \"Performance Metrix\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6de73d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "2:46:30\n",
    "\"EDA\" -> \"FE\" -> \"FS\" -> \"Model Creation\"-> \"pickle file\" -> \"flask app\"\n",
    "\n",
    "\n",
    "\n",
    "After Creating the Model How shoud we used in the Productin Grade ?\n",
    "Ans:=\n",
    "    convert the \"model\" into \"pickle file\" there also different different\n",
    "    file format like \".sav \"(serilize object format) just to save the size\n",
    "    of the \"model\",we bassically say is has \"pickling\",\".h5\" file like\n",
    "    different different file will be there ,\n",
    "    \n",
    "what happens with respect to pickling ?\n",
    "\n",
    "Ans:=\n",
    "    After creating our \"Model\" when ever it takes an input it gives as an\n",
    "    output, internally inside the \"model\" we have have lot of \"mathemetical\"\n",
    "    calculations and what ever \"algorithem\" that we used that will be there\n",
    "    So that \"mathemetical calculations\" will be \"saved\" in a \"pickle file\",\n",
    "    so that when ever we want i can use that \"file\", \n",
    "    \n",
    "    Note :=\n",
    "        pickle will convert the object into bytes\n",
    "    \n",
    "    in real world \"Application\" After \"Model\" is getting \"created\" with the\n",
    "    help of frantend \"Application\" ex:-(\"flack\"), So from this \"flask\". let say\n",
    "    my \"pickle file\" is created i create an \"Api\" with the help of \"flask\",\n",
    "    inside this \"Api\" i can load this \"pickle file\", so finaly when we hit \n",
    "    this \"Api\"  simply give it to the input and get the output that will be\n",
    "    our \"prediction\" ,\n",
    "    \n",
    "    \n",
    "    \n",
    "What pickle will do ?\n",
    "Ans:=\n",
    "    it will converthe entire \"Model\" into a \"Serilized format\" with extenction\n",
    "    of \".pkl\" and save it in the \"Bytes\"\n",
    "    \n",
    "    After creating my model \"pickle file\" ill be giving an input ill be\n",
    "    getting an output here \"prediction\" will happen like\n",
    "    if i give \"batch\" of \"inputs\" i will get a \"batch\" of \"outputs\" \n",
    "    if i give \"single\" of \"inputs\" i will get a \"single\" of \"outputs\". \n",
    "    After \"pickle file get ready\" with the help of \"flask\" we create one\n",
    "    \"API\" and we load the \"pickle file\" into an \"API\" we give the input \n",
    "    it can from \"postman\", it can com from many things ,after taking the \n",
    "    input we do the \"prediction\" from the \"pickle file\" and finally get \n",
    "    the output,\n",
    "    \n",
    "    Note :=\n",
    "        After reating an api use it where ever you want,\n",
    "        \n",
    "        1.How do we load the pickle file ?\n",
    "        2.how do we take the input \n",
    "           based on input there are two thigs \n",
    "             1. we can also take/pass a \"batch input\" to the model(pklfile)\n",
    "             2. we can also take/pass a \"single input\" to the model(pklfile)\n",
    "        3. based on inputs we can also get the output\n",
    "\n",
    "    \n",
    "    \n",
    "why we need to store ML MODEL in pikcle file not Excel or any other ?\n",
    "\n",
    " \"pickle\" file is a \"serilized maner format\" so that when it is \n",
    "\"serilized format\" it will be able \"load\" and basiically \"exicute\" \n",
    "in the \"API\" very \"easly\", its hardly store in \"BYTES\" if we store\n",
    "it in exsel or something it could be a \"large\"\n",
    "    \n",
    "    \n",
    "what is machine learning model?\n",
    "\n",
    "A machine learning \"model\" is a file that has been \"trained\" to recognize \n",
    "certain types of \"patterns\". we Actually \"train a model\" over a set of data, \n",
    "providing it to some \"Algorithms\" that it can used to reason over\n",
    "and learn from those data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e9dfa7",
   "metadata": {},
   "source": [
    "# SVM Kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58edb492",
   "metadata": {},
   "outputs": [],
   "source": [
    "    1. \"Sopport_Vector_Machine\"(SVM)\n",
    "    \n",
    "    \"Sopport_Vector_Machine\"(SVM) sovle \"classification\"  and \n",
    "    \"Regression\" problem also,\n",
    "    \n",
    "    and if solving this for \"classification\" problem\n",
    "    statement that time we say this as a \"SVC\" if we are solving \n",
    "    \"Regression\" problem that time we say this as \"SVR\"\n",
    "    \n",
    "SVM Kernal :=\n",
    "    \n",
    "    \n",
    "I have dataset like this  let say\n",
    "\n",
    "in \"Sopport_Vector_Machine\"(SVM) when ever we try to create \"strait line\"\n",
    "the \"Kernal\" = \"linear\" by defult\n",
    "     \n",
    "     [SMV] ----> [\"Kernal\" = \"linear\"]\n",
    "        \n",
    "        when the \"Kernal\" you select as \"linear\" inshot you should\n",
    "        going to basically creating a \"Best fit line\" along with the \n",
    "        \"Marginal plane\",\n",
    "\n",
    " SVM has one amaging thing\n",
    "       X2\n",
    "        ^\n",
    "        |              let say my datapoints will looks like this\n",
    "        |      \n",
    "        |     â— â— â— \n",
    "        |   â—  * *  â—      are we able to make \"Best fit line\" for this ?\n",
    "        |  â—  *   *  â—      \n",
    "        |   â—  * *  â—       Ans := yes  with the hepl of \n",
    "        |     â— â— â—                \"Support Vector Machine\" its posible there \n",
    "        |                           is somthing amezing in \"SVM\" which called as \n",
    "        |--------------------> X1   \"SVM_kernals\" SVM_kernal helps it converts \n",
    "                                   the \"lower_dimension\" into \"higher_dimension\"\n",
    "    \n",
    "after creating \"best fit line\" the Accuracy is oproximatly = 50% \n",
    "this is with respect to Kernal=\"linear\",\n",
    "\n",
    " so   \n",
    "in particuler Scenario how to solve this proble ?\n",
    "    \n",
    "                     ^\n",
    "                     |              \n",
    "                     |       *  *   \n",
    "                     |     *      *   \n",
    "                     |       *  * \n",
    "                     |  /--------------------/ -----> \"hyper plane\"\n",
    "                     | /--------------------/\n",
    "                     |       â—   â—\n",
    "                     |    â—         â—\n",
    "                     |       â—   â—\n",
    "                     |                   \n",
    "                     /-------------------->\n",
    "                    /\n",
    "                   /    when you have like this you can create\n",
    "                  /     hyper_plane like in shown\n",
    "                 /  \n",
    "                \n",
    "Here the aim of SVM  kernal is that ?\n",
    "Ans :=\n",
    "    in the \"SVM Kernal\" aim is we will try to do some data transformation\n",
    "    in this data Tranformation we convert \"lower dimention\" to the\n",
    "    \"higher dimention\".\n",
    "    \n",
    "\n",
    "ther is one Algorothem \"PCA\":=\n",
    "    PCA(principle componant analasis) this converts from \n",
    "    \"higher dimention\" into \"lower dimention\" (its unsuperwised ML Alrgm)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "how \"SVM Kernal\" convert to a \"lower dimention\" to a \"higher dimention\" ?    \n",
    "\n",
    "Ans:=              \n",
    "                    |--> hyper plane \n",
    "                    |\n",
    "    -----â–ª--â–ª-â–ª-â–ª-â–ª-|-â—-â—-â—-â—--------x\n",
    "                    |                   its a 1 \"dimension\"\n",
    "        \n",
    "        in this 1 dimension we create 1 simple \"hyper line\" to divede\n",
    "        the \"points\" and apply any \"linear\",\"logistic\",\"SVM\"..etc\n",
    "        \n",
    "  Now my points like this\n",
    "\n",
    "                  \n",
    "                    \n",
    "    ----â–ª--â–ª-â–ª-â–ª-â–ª--â—-â—-â—-â—--â–ª-â–ª-â–ª-â–ª---x1\n",
    "    \n",
    "    the points are \"jumbbaled\" Now how do i convert this into\n",
    "    2D-dimention and try to solve a problem.\n",
    "    \n",
    "    if i do plot(x1)Â² the points look like\n",
    "    \n",
    "   (x1)Â² \n",
    "    |\n",
    "    |   â–ª                          â–ª\n",
    "    |     â–ª                      â–ª    if i get this kind of curv now we \n",
    "    |       â–ª                  â–ª     create \"hyper_plane\" easyly\n",
    "    |         â–ª              â–ª\n",
    "    | ------------------------------  here we applyed simple \"Sqare\"\n",
    "    |            â—        â—          technique if we want to convert 2-d \n",
    "    |               â—  â—             3-d then what technique we have to \n",
    "    |                                apply ?\n",
    "    |\n",
    "    |\n",
    "   -|----â–ª--â–ª-â–ª-â–ª--â—-â—-â—-â—--â–ª-â–ª-â–ª-â–ª--->x1\n",
    "\n",
    "\n",
    "\n",
    "    \"1 dimention\" to \"2 dimention\" for converting we bassically\n",
    "    apply \"simple (square)Â² thechnics\"\n",
    "    \n",
    "    but 2D dimention to 3D dimention to 4D whenever those \n",
    "    kind of problem state ments are there specifically \n",
    "    we discouss about 3 thing ,\n",
    "    \n",
    "        1. Polynomial\n",
    "        2. RBF(\"Radia Basis fuunction\")\n",
    "        3. Sigmoid Kernal\n",
    "        \n",
    "in \"polynomnal\" and \"RBF\" we are applying one \"mathemetical formula\"\n",
    "when you apply \"mathematical formula\" then you get the entire \"Kernal\"\n",
    "things\n",
    "\n",
    "1. \"Polynomial\",\n",
    "\n",
    "lets say i have 2 features \n",
    "\n",
    "   X = { x1     x2 } x1, x2 rondom variable/features\n",
    "    \n",
    "    \n",
    "    x1       x2     y         [:. x1,x2 = \"independet features\"]\n",
    "                              [. y      = \"dependent/ouput feature\"]\n",
    "        \n",
    "                              [:.x,x2 are here \"2d-dimesions\"]\n",
    "            \n",
    "                              \"x2\"\n",
    "                               |\n",
    "                               |          if we applying \"Polynomial\" formula\n",
    "                               |---->\"x1\"   (xT.x + 1)**d -->it will converted\n",
    "                                           like \"3d-dimention\" points like\n",
    "                                           (\"x1Â²  x1x2  x2Â² \")\n",
    "                                 \"x1x2\"\n",
    "                                    |\n",
    "                                    |----\"x1Â²\"\n",
    "                                   /\n",
    "                                  /\n",
    "                                \"x2Â²\"   \n",
    "                                    \n",
    "                as we know x1,x2 are 2D -\"2dimentions\" points\n",
    "                \n",
    "Now can we convert this \"2d-dimension\" to \"3d-dimention\" ?\n",
    "             \n",
    "    \"Polynomial kernal\" = (xT.x + 1)**d \n",
    "    \n",
    "                                [:.d is nothing but \"dimesion\"]\n",
    "    \n",
    "                                \n",
    "                    \n",
    "    |x1|           | x1Â²    x1x2|\n",
    "    |  |[x1 x2] =  |            | so in this x1x2,x1x2 are same so we use\n",
    "    |x2|           |x1x2     x2Â²| x1Â² , x1x2 , x2Â² this 3 turms\n",
    "    \n",
    "    \n",
    "i will be having\n",
    "\n",
    "\"x1\"   \"x2\" apart from that  we create \"x1Â²  x1x2  x2Â² \"\n",
    "\n",
    "for sovling problem statement we will take{x1Â²  x1x2  x2Â²}\n",
    "this 3, and then we will try to create a \"hyper plane\", which\n",
    "is \"Linear hyper plane\", b-coze by this i will be getting\n",
    "\"3D\" -\"3dimentions\".\n",
    "and we are applying the formula so that we are getting \n",
    "\"points\" like\n",
    "\n",
    "                    \"x2Â²\" \n",
    "                     |        \\          like this points will get created \n",
    "                     |    â— â—  \\ â–ª â–ª    then you can easyly create \n",
    "                     |   â—      \\â–ª  â–ª   'hyper plane'\n",
    "                     |   â—       \\â–ª â–ª\n",
    "                     |    â—       \\\n",
    "                     |      â—  â—   \\\n",
    "                     |\n",
    "                     /-------------------> \"x1Â²\"\n",
    "                    /\n",
    "                   /    this is a manual proses, \n",
    "                  /   \n",
    "               \"x1x2\"   \n",
    "\n",
    "done by manually in \"sklearn\" you just write [Kernal=\"poly\"]\n",
    "this entire [\"x1Â²  x1x2  x2Â² \"] \"calculations\" done \"internally\"\n",
    "we have scene how it happens \"manually\" upper\n",
    "\n",
    "2.RBF- Kernal:=\n",
    "    \n",
    "what is this \"RBF-Kernal\" ?\n",
    "\n",
    "Ans:= RBF stands for \"Radia Basis fuunction\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd199710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba5e547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ae58a84",
   "metadata": {},
   "source": [
    "# Bagging & Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67258ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Decision Tree\":-\n",
    "        \n",
    "                      ðŸ”˜    \n",
    "                      / \\  \\   \n",
    "                     /   \\  \\        \n",
    "                    /     \\\n",
    "                  ðŸ”˜      ðŸ”˜\n",
    "                        / / \\\n",
    "                         /   \\\n",
    "                      / ðŸ”˜   ðŸ”˜ \n",
    "                     /  /      \\\n",
    "                       /        \\\n",
    "                      /          \\\n",
    "                    ðŸ”˜           ðŸ”˜\n",
    "    \n",
    "    \n",
    "in \"Decision_Tree\" ,if i keep on constracting \"Decision_Tree\" to its \n",
    "complete \"depth\"  it will be creating \"Over_fitting\", \n",
    "to Reduce this \"Overfitting\" we do \"hyper perameter tunning \" with \n",
    "\"GridSeachrCV\" like \"pri_pronning\",\"post_pronning\" we set up the \n",
    "\"max_depth\" and all, in case of \"overfitting\" the condition is like\n",
    "\"low baise\" and  \"high variance\" ,\n",
    "\n",
    "\n",
    "\n",
    "Aim is that  in    \n",
    "we will constract the \"Decision_Tree\"  to its complete \"depth\" and\n",
    "we convert this  \"high variance \" into 'low variance' now in order\n",
    "to this we will be using some thing callsed somthing called as\n",
    "\n",
    "     \"ENSENBLE TECHNICS\"\n",
    "    \n",
    "What exactly the Ensemble techniqes?\n",
    "\n",
    "imp :=\n",
    "    ENSENBLE TECHNICS :=\n",
    "        in \"Ensenble Technic\" we have 2 thing and you can also use\n",
    "        own \"costum\" \"Ensemble Technqe\" also,\n",
    "        \n",
    "        1. \"Bagging\" \n",
    "        2. \"Boosting\"\n",
    "        \n",
    "            \n",
    "                   ENSENBLE TECHNICS\n",
    "                           |\n",
    "         |-----------------|-----------------|\n",
    "         |                                   |\n",
    "       \"Bagging\"                            \"Boosting\" \n",
    "    \n",
    "  \n",
    "1.\"Bagging\" :=\n",
    "    \n",
    "now in \"Bagging\" instead of applying \"one algorithem\" for a \n",
    "specific \"data_set\" will try to apply \"many algorithems\" and\n",
    "the output per soppose lat say  classification problem\n",
    "\n",
    "let say i have \"specific dataset\"  \n",
    "\n",
    "    |-------------------|      let say this is  my \"dataset\"\n",
    "    |                   |--row1\n",
    "    |-------------------|           \"d\" = size of dataset \n",
    "    |-------------------|\n",
    "    |                   |-->row2    \"d\" basically means that many\n",
    "    |-------------------|            number of \"datapoints\"\n",
    "    |-------------------|\n",
    "    |                   |-->rown\n",
    "    |-------------------|\n",
    "\n",
    "in \"Bagging\" what we do is that we create \"Many algorithems\"\n",
    "like \"parlally\" and it may be repeated it may not be reapeated.\n",
    "\n",
    "                             |--------|\n",
    "                             |\"alrgm\" |---> this is mt \"Dicision_Tree\"\n",
    "                         /-->|   1    | this \"Alrm\" giving 0\n",
    "                        /    |--------| after trainig this o/p giving \n",
    "                   \"d`\"/                 with respect to the \"test_data\"\n",
    "                      /       |--------|\n",
    "                     /\"d``\"   |\"alrgm\" |---> this is mt \"Linear\"\n",
    "   dataset(d)       /    /--->|   2    |   this \"Alrm\" giving 0\n",
    " |-------------------|  /     |--------| after trainig this o/p giving \n",
    " |-------------------|-/                 with respect to the \"test_data\"\n",
    " |-------------------|-\\     |--------|\n",
    " |-------------------|  \\    |\"alrgm\" |---> this is mt \"Logisic\"\n",
    " |-------------------|   \\-->|   3    |   this \"Alrm\" giving 1\n",
    "                     \\       |--------|        \n",
    "                      \\\n",
    "                       \\     |--------|\n",
    "                        \\    |\"alrgm\" |---> this is mt \"SVM\"\n",
    "                         \\-->|   4    |   this \"Alrm\" giving 0\n",
    "                             |--------|\n",
    "        \n",
    "    Now to \"each algorithem\" we give Dataset \"d`\"(dash)\n",
    "        \n",
    "    we can say \"d`\"(dash) < less then \"d\" (d`<d)\n",
    "            or \n",
    "    \"d`\"(dash) that bassically means we are going to \"d`\"(dash)\n",
    "    its \"less then\" \"<\" d,\n",
    "           or\n",
    "    the \"sample\" of data(d) from \"dataset\" we are going to give it\n",
    "    to the \"Alrgm\"\n",
    "    \n",
    "    like we provide \"d`\" to 1 \"Alrgm\" \"d``\" another \"Alrgm\" and note\n",
    "    this \"d``\" will have some records(rows) of \"d`\"(dass)\n",
    "    like we give \n",
    "    \n",
    "    like each Algorithm have its own saparate dataset (\"rocords\") \n",
    "    it may \"reapeted\" it may not be \"repeated\" but we are giing\n",
    "    sample of \"dataset\".\n",
    "    \n",
    "    \n",
    "So the final output will the \"Majority\" is 0 of all the \"algorithems\"\n",
    "what the algorithem what it is saying. so this basically  called as\n",
    "\"Majority Voting classifier\"\n",
    "\n",
    "(V.V.IMP point)\n",
    "in the case of \"Regression\" what will happen ?\n",
    "Ans :=\n",
    "    in the case of \"Regression\" the \"Avarage\"(mean) of all the \"output\"\n",
    "    \"values\" will be concidered\n",
    "    \n",
    "    In \"Bagging\" each and every Algorihem will happen in \"Paralel\" only\n",
    "    its not \"Sequeantial\" and again the Algorithems like it may be \n",
    "    repeated or it may not be repeated.\n",
    "    \n",
    "    \n",
    "-----------------------------------------------------------------------    \n",
    "    \n",
    "    \n",
    "    \n",
    "2.\"Boosting\" :=\n",
    "    \n",
    "      alrgm-1         alrgm-2        alrgm-3     alrgm-4      alrgm-5\n",
    "    |--------|      |----------|    |--------|   |-------|    |------|\n",
    "    | physics|--->  |geography |    |        |   |       |    |      |\n",
    "    |  guy   |      | guy      |--->|        |-->|       |--->|      |\n",
    "    |--------|      |----------|    |--------|   |-------|    |------|\n",
    "       |                 |                                         |\n",
    "       |                 |                                         |\n",
    "   \"weak learner\"     \"weak learner\"                    \"strong learner\"\n",
    "    \n",
    "lets say we are playng \"kon banega korode pathi \"\n",
    "\n",
    "ive got a \"quetion\" from \"histri subject\" i dont no i asked for a help\n",
    "and my quetion went to \"physics guy\" --> no but give some idea\n",
    "after this pysics guy the quetion is went to \"geography guy\"\n",
    "he may be provide some more \"information\" based on \"physics guy\",\n",
    "\n",
    "here \"pysics guy\" is \"weak learner\" and \"geography\" some \"weak learner\",\n",
    "like this \"information\" will keep on getting \"build\" this entire \n",
    "\"combination\" will finally become a \"strong learner\", over here \n",
    "\"Sequential Algrithem\" will getting \"applyed\"\n",
    "\n",
    "\n",
    "Bagging :=\n",
    "    in \"Bagging\" we need to understand \"Random Forest\" Alrgm\n",
    "    \n",
    "1.Random Forest Classification and Regression\n",
    "\n",
    "Boosting :=\n",
    "    in Boosting there are different different \"algorithems\"\n",
    "    \n",
    "1. Ada_boost\n",
    "2. Cat_boost\n",
    "3. Gradient_boost\n",
    "4. XG_boost      ----> this all can be used for \"Classification\"\n",
    "                     and \"Regression\" problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798f1344",
   "metadata": {},
   "source": [
    "# Bagging\n",
    "1.Random Forest Classification and Regression\n",
    "\n",
    "# Boosting\n",
    "\n",
    "1. Ada_boost\n",
    "2. Cat_boost\n",
    "3. Gradient_boost\n",
    "4. XG_boost\n",
    "\n",
    "## Random Forest Classification and Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b61fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.Random Forest Classification and Regression\n",
    "\n",
    "Random Forest :=\n",
    "    Random Forest \"Classification\" or \"Regression\" is bassically \"Bagging\" \n",
    "    technic\n",
    "\n",
    "what happens in Rondom forest ?\n",
    "\n",
    "    [:. \"d\" = size of dataset  ]  \n",
    "    [:. \"f\" = N-number of features] \n",
    "\n",
    "                        \"d`\" |--------|\n",
    "                        \"f`\" |        |---> this is my \"Dicision_Tree_1\"\n",
    "                         /-->|  DT1   | \n",
    "                        /    |--------| \n",
    " f=Nno.of (\"features\") /                 \n",
    "                      /  \"d``\" |--------|\n",
    "  dataset(d) which   /   \"f``\" |  DT2   |---> this is my \"Dicision_Tree_2\"\n",
    "has lot of \"rcords\" /    /---->|        |   \n",
    " |-------------------|  /      |--------|  \n",
    " |-------------------|-/                 \n",
    " |-------------------|-\\  \"d```\"|--------|\n",
    " |-------------------|  \\ \"f```\"|  DT3   |---> this is my \"Dicision_Tree_3\"\n",
    " |-------------------|   \\----->|        |                  :\n",
    "                     \\          |--------|                  :\n",
    "                      \\                                     :\n",
    "                       \\  \"d````\"|--------|                 :\n",
    "                        \\ \"d````\"|  DT4   |---> this is my \"Dicision_Tree_n\"\n",
    "                         \\------>|        |   \n",
    "                                 |--------|\n",
    "                        \n",
    "in \"Rondom Forest\" we have somthing called as \"Dicision_Trees\"\n",
    "by defult (100) \"Decission_Trees\" in the \"Rondom Forest\",\n",
    "\n",
    "Now this is with respect \"Classification\"\n",
    "\n",
    "in classification what happens ?\n",
    "\n",
    "Ans:=\n",
    "    \n",
    "    the \"Sample\" of dataset (\"d`\")dash will provide to \"Dicision_Tree1\"\n",
    "    let say and apart from this will giving the (\"f`\")dash features \"f`\"\n",
    "    bassically means sub set of \"features\". not give the etire \"features\"\n",
    "    will give will give sub-set(sample) of \"feature\"(\"f`\") will \"less then\"\n",
    "    (\"f\")(\"f`\"< \"f\").\n",
    "    \n",
    "        [:. (\"d`\")dash basically means subset of \"row\"s/datapoints  ]\n",
    "        [:. (\"f`\")dash basically means subset of \"colunms\"s/features]\n",
    "\n",
    "    similarly to the next \"Dicision_Tree\" we will give  \"d``\"(dash) and\n",
    "    (\"f``\")dash similarly to next \"Dicision_Tree\" we will give \"f```\" and\n",
    "    \"d```\" of sample/row and colunms/feature we will give.\n",
    "    \n",
    "    but here in all the 'd`' and \"f`\" in that some of the \"features\"  may\n",
    "    get \"repeated\" or some of the \"datapoints\"/rows  may get \"repeated\",\n",
    "    \n",
    "    So here every \"Decission_Tree\" is given its own \"Subset\" of\n",
    "    \"dataset\"(d`) and \"features\" and then we train \"Decission_Trees\"\n",
    "    of our \"entire Model\".\n",
    "\n",
    "    \n",
    "How it happens with the test data ?\n",
    "\n",
    "Ans :=\n",
    "    it will go all the \"Decission_Trees\",\n",
    "    \n",
    "                        \"d`\" |--------|\n",
    "                        \"f`\" |        |---> this is my \"Dicision_Tree_1\"\n",
    "                         /-->| DT1    | --> this \"Decission_Tree\" give\n",
    "                        /    |--------|     output as one = 1\n",
    " f=Nno.of (\"features\") /                 \n",
    "                      /  \"d``\" |--------|\n",
    "  dataset(d) which   /   \"f``\" | DT2    |---> this is my \"Dicision_Tree_2\"\n",
    "has lot of \"rcords\" /    /---->|        |    output as one = 1\n",
    " |-------------------|  /      |--------|  \n",
    " |-------------------|-/                 \n",
    " |-------------------|-\\  \"d```\"|--------|\n",
    " |-------------------|  \\ \"f```\"|        |---> this is my \"Dicision_Tree_3\"\n",
    " |-------------------|   \\----->| DT3    |      output as one = 0           \n",
    "                     \\          |--------|                  :\n",
    "                      \\                                     :\n",
    "                       \\  \"d````\"|--------|                 :\n",
    "                        \\ \"d````\"|        |---> this is my \"Dicision_Tree_n\"\n",
    "                         \\------>| DT4    |   output as one = 1\n",
    "                                 |--------|\n",
    "                                \n",
    "Note :-\n",
    "    if there is a \"equal Tie\" with respect to \"Decission_Trees\" outputs if\n",
    "    happens there are some \"interanal\" some parameters will be there which \n",
    "    will be able to help you out\n",
    "    \n",
    "    which will be the maximum \"outputs\" here 1 means again we have\n",
    "    \"Majority Voting classifier\" will be there,\n",
    "\n",
    "with the help of \"Majority Voting classifier\" you will get 1 or 0.\n",
    "that will be our output,\n",
    "-----------------------------------------------------------\n",
    "NOTE :=\n",
    "    in \"Bagging\" we can can use any kinda of \"Algorithem\".\n",
    "    so this becomes a \"COSTUME ENSEMBLE TECHNIQUE\".\n",
    "    \n",
    "    but in \"Rondom Forest\" we use \"Decission_Trees\"\n",
    "------------------------------------------------------------\n",
    "\n",
    "So finally if we are using these many \"Decission_Trees\" in \"Rondom\"\n",
    "\"Forest\" my \"Accuracy\" will be good, bcoz every \"Decission_Tree\" in \n",
    "\"Rondom Forest\" has its own \"Unique\" things,so definatly it will \n",
    "able to give as a \"good Accuracy\",\n",
    "\n",
    "if we have these many \"Decission_Trees\" in \"Rondom Forest\" we will\n",
    "be getting 'low Bais' and \"low Variance\",if we do along with some \"hyper\"\n",
    "\"parameter tuning\",\n",
    "\n",
    "\n",
    "Rondom Forest \"Regressor\" :-\n",
    "    \n",
    "in case of \"Rondom Forest_Regresson\" with respect to \"Decission_Trees\"\n",
    "Each and every \"values\" are different like \"continous\", So if we take the\n",
    "\"Mean\" of it will be the  answer\n",
    "\n",
    "V.V.IMP :\n",
    "    What ever \"hyper parameters\" that your using in \"Decission_Tree\"\n",
    "    that all the \"parameters\" will apply to  \"Rondom Forest\"\n",
    "    \"Decission_Trees\",\n",
    "    \n",
    "is there a Scenorio you can apply in some kind of things in\n",
    "only some  \"Decission_Trees\" in \"Rondom Forest\" ?\n",
    "Ans :=\n",
    "    No , What ever\" hyper parameter Tuning\" your Applying it will\n",
    "    get \"Applyed\" to the \"entire Decission_Tree\"\n",
    "    \n",
    "--------------------------------------------------------------------------    \n",
    "what is happening when we are using many \"Decission_trees\" in \n",
    "Random Forest ?\n",
    "Ans:= \n",
    "Suppose if i am creating decission tree to its complete depth it has \n",
    "    1. low baise\n",
    "    2. high variance\n",
    "\n",
    "\"low baise\" say if i am creating decission to its complete depth  it will\n",
    "get properly  trained for our trainig dataset so the traning error will \n",
    "be very less so this leads to \"overfitting\"\n",
    "\n",
    "\"high variance\" say whenever we get a new test_dataset there learger \n",
    "amount of errors\n",
    "\n",
    "in random forest i am bassically using multiple DTs each and ever DT has \n",
    "high Variance but when we combine all decission Trees with respect\n",
    "mejority ovtting this \"high variance\" will converted into \"low variance\"\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d759bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04e28ce7",
   "metadata": {},
   "source": [
    "# Performance Metrix :=\n",
    "    1. ROC and AUC curve\n",
    "    \n",
    "    roc_auc_curv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe88a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. \"ROC_AUC_CURV\" \n",
    "                       for healthcare problem state treshholde will be\n",
    "               model has       [0,0.2,0.4,0.7,0.8,1]\n",
    "real_opt      predic_opt         >0      >0.2       >0.4\n",
    "-------------------------     ^y(0)     ^y(0.2)   ^y(0.4)\n",
    "Y                ^Y        treshhold    \n",
    "1               0.8             1          1         1\n",
    "0               0.96            1          1         1 \n",
    "1               0.4             1          1         0\n",
    "1               0.3             1          1         0\n",
    "0               0.2             1          0         0\n",
    "1               0.7             1          1         1\n",
    "\n",
    "in \"heath care\" problem the \"Probability\" should be \"varie\"\n",
    "in this particular case we need to find out the Trheshhold\n",
    "\n",
    "How do i findout the \"threshhold\" ?\n",
    "which is the suitable threshhold, how do i check it so for that we \n",
    "using \"roc_auc_curv\",\n",
    "\n",
    "\"AUC\" stands for \"area under the curv\"\n",
    "\"ROC\" stands for \"Reciever operating charecteristics curv\"\n",
    "\n",
    "my \"threshold\" value always ranging b/w [ 0 to 1]\n",
    "\n",
    "so we can check threshold as [0,0.2,0.4,0.6,0.8,1] this bassically means\n",
    "when my \"opt\" \"less then\" (< 4.0) then i take it as 0 when my o/p \"greter\"\n",
    "then  (>4.0) then  i take it as 1\n",
    "\n",
    "V.V.IMP\n",
    "--------------------------------------------------------\n",
    "\"ROC_AUC_CURV\" should get applyed/used for every \"Classification\"\n",
    "problem statements, it will help you to deside \"thresh hold\"(points)\n",
    "and how your \"model performs\" well\n",
    "\n",
    "\"AUC\" is used for the picking up the \"thresh hold\"(points)\n",
    "AUC (\"Aria unde the cure\" ) bassically says how good your model is\n",
    "-------------------------------------------------------------------\n",
    "@Sensitivity :=\n",
    "    (true positive rate) refers to the probability of \n",
    "    a positive test, conditioned on truly being positive.\n",
    "           or\n",
    "    \"TPR\" is called as \"sensitivity\" then 1-\"TPR\" is called as\n",
    "    \"specisivity\"\n",
    "    \n",
    "@Specificity :=\n",
    "    (true negative rate) refers to the probability of a\n",
    "    negative test, conditioned on truly being negative.\n",
    "    \n",
    "    \n",
    "    \n",
    "calculate \"TPR\" and \"FPR\"  := if tresh hold is   ^y(0)  \n",
    "                                                          actual values\n",
    "this is called as \"sensitivity\"         predicted------------\n",
    "                         TP         4      value | Tp |FP   |\n",
    "lets calculate \"TPR\" =  --------- =--- = 1       |----|-----|\n",
    "                       TP + FN      4+0          | FN | TN  | cofusion\n",
    "                                                 ------------ matrix\n",
    "\n",
    "\n",
    "Now we have to calulate the \"FPR\" b-coz \"roc_auc_curv\" in this we have\n",
    "to create graph with the help of \"TPR\" and \"FPR\"\n",
    "\n",
    "\n",
    "\"FPR\" is called as \"Specificity\"    \n",
    "\n",
    "                           FP         2\n",
    "lets calculate \"FPR\" =  --------- =  --- = 1\n",
    "                         FP + TN     2+0 \n",
    "    \n",
    "    now based on \"TPR\" and \"FPR\" if i draw graph like \n",
    "         TPR\n",
    "           ^\n",
    "           |\n",
    "         1-|-----------*(1,1) \n",
    "           |           |\n",
    "           |           | \n",
    "           |           |\n",
    "           |-----------|-->FPR\n",
    "           0           1\n",
    "                \n",
    "calculate \"TPR\" and \"FPR\"  :=if tresh hold is   ^y(0.2) \n",
    "    \n",
    "                         TP         4\n",
    "lets calculate TPR =  --------- =  --- = 1 \n",
    "                        TP+FN      4+0 \n",
    "   \n",
    "                         FP         1\n",
    "lets calculate FPR =  --------- =  --- = 1/2 = 0.5\n",
    "                       FP + TN     1+1  \n",
    "    \n",
    "           TPR\n",
    "           ^\n",
    "           |\n",
    "         1----------*(1,0.5) \n",
    "           |        |\n",
    "           |        |\n",
    "           |        |\n",
    "           |--------|-------->FPR\n",
    "                   0.5       \n",
    "                \n",
    "calculate \"TPR\" and \"FPR\" :=if tresh hold is   ^y(0.4) \n",
    "    \n",
    "                          TP        2 \n",
    "lets calculate TPR =  --------- =  --- = 0.5\n",
    "                       TP + FN     2+2 \n",
    "   \n",
    "                         FP         1\n",
    "lets calculate FPR =  --------- =  --- = 1/2 = 0.5\n",
    "                       FP + TN     1+1 \n",
    "    \n",
    "               TPR\n",
    "           ^\n",
    "        1--|--\n",
    "           |    \n",
    "           |\n",
    "        0.5---     *(0.5,0.5)\n",
    "           |\n",
    "           | \n",
    "           |-------|------>FPR\n",
    "                  0.5 \n",
    "                \n",
    "                \n",
    "now combine this all \"thresh hold\" point similarly all\n",
    "this will become like bolow one\n",
    "\n",
    "    TPR\n",
    "     ^            (1,0.5)\n",
    "  1--|---        *-------------*(1,1)\n",
    "     |           |             |\n",
    "     |           |             | \"Roc Curv\" greater then the \"Middle\" line\n",
    "     |           |             | the \"roc\" curv if it is bellow the midline \n",
    " 0.5-------------*(0.5,0.5)    | means model predicting \"less then\" the 50%\n",
    "     |                         | \n",
    "     |                      -------->this aria called \n",
    "     |                         |        \"aria under the curve\"\n",
    "     |-----------|-------------|-->FPR   the more \"aria under the under\"\n",
    "                      0.5            1    the more better your model is\n",
    "                                         \n",
    "    finaly  it formform 90% good becoz by seeing the \"Area\"\n",
    "    out of 100 only some \"Area\" is missing\n",
    "    \n",
    "    Now question raises what trheshold we need to choose ?\n",
    "    \n",
    "    Ans :=\n",
    "        that will be based on \"domain Experties\"\n",
    "        \n",
    "        soppose the \"Domain Expertiece\" says that they want focuss more on\n",
    "        True +ve cases then this point of a time \"TPR\" true +ve rate should\n",
    "        be \"high\".\n",
    "        \n",
    "        The \"Domain Expertiece\" says that i dont want care about \"FPR\" but he\n",
    "        want \"TPR\" is very high\n",
    "        \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4a33f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109f62b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb21dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Agenda \n",
    "1. Naive Bayes Algorithem [\"classification Algorithem\"](NLP)->Natural Language Processing\n",
    "2. Practicals {\"Simple\"/\"Linear_regration\" , \"ridge\",\"lasso\",\"elasticnet\",\"logistic\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d1fd7d",
   "metadata": {},
   "source": [
    "# 1. Naive Bayes Algorithem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b55ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "all the assumptions with respect to \"Linear Regression\" same will get applyed \n",
    "to \"Logistic Regrssion\".\n",
    "\n",
    "\n",
    "\n",
    "1. Naive_Bayes Algorithem {\"Intution\"}\n",
    "\n",
    "Probabulity :=\n",
    "    \n",
    "    let say  rolling a dice the possible values may come = {1,2,3,4,5,6}\n",
    "    \n",
    "what is Propability of getting 1\n",
    "\n",
    "Pr(1) = 1 / 6  on top we only get 1 time 1 value only we dont get like 1 and 3\n",
    "1 and 5 no right\n",
    "\n",
    "     Pr(2) = 1 / 6 , Pr(3) = 1 / 6 so these all are \"independent events\"\n",
    "    \n",
    "\"Indepent_events\" :=\n",
    "    \n",
    "    Pr(1) = 1 / 6   Pr(2) = 1 / 6  Pr(3) = 1 / 6\n",
    "    all this events are \"Independent events\" be coz all time \n",
    "    we get 1 / 6 every time if i rolling a dice it has 1 / 6 only\n",
    "    so this is \"indepent_events\"\n",
    "    \n",
    "    \n",
    "\"Dependent_Events\" :=\n",
    "    \n",
    "    i have a bag of \"marbules\" in that \"3 yellow\" marbules\n",
    "    \"2 green\" marbules \n",
    "    \n",
    "    what is the Probabulity of taking out the \"red marbule\"\n",
    "    \n",
    "    P_r(red) = 0/6 = 0 only\n",
    "    \n",
    "    what is the Probabulity of taking out the \"yellow marbule\"\n",
    "    \n",
    "    P_r(yellow) = 3 / 6 = 1/2 let say this is my 1st event\n",
    "    \n",
    "    after complete 1st evet How many marble left over in bag?\n",
    "    \n",
    "    Ans := its having 5 \"marbules\" (2 \"yellow\",3 \"green\")\n",
    "    \n",
    "    now after completion of \"1st_event\" what is the Probabulity \n",
    "    of taking out the \"green marbule\" where in given_bag \"yellow\" is\n",
    "    already taken out\n",
    "    so\n",
    "    \n",
    "    P_r(green/yellow) = 3 / 5 this is my 2nd event\n",
    "    \n",
    "why this we need ?\n",
    "\n",
    "    what is the Probabulity of taking out the \"yellow\" and then\n",
    "    taking out the \"green\" marbule\n",
    "    \n",
    "    if i write based upper example \n",
    "\n",
    "    => P(Y & G) = P(Y)*P(G/Y)\n",
    "    \n",
    "    P_r(yellow & green ) = P_r(yellow) * P_r(green/yellow)\n",
    "            |\n",
    "        this is with respect to \"Dependent_event\"\n",
    "        \n",
    "        so totaly 1/2 * 3/5  3 / 10 = 0.3 \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "this is called \"Conditional_probabulity\" its super imp for \n",
    "\"Naive_Bayes\" Algorithem\n",
    "    \n",
    "P_r(a & b) = P_r(a)*P_r(b/a) this is called \"conditional_probabulity\"\n",
    "\n",
    "                     1/2 * 3/5 = 3 / 10 = 0.3\n",
    "    \n",
    "        \n",
    "Can i write     P_r(a & b)  =  P_r(b & a) ------>yes its similar\n",
    "\n",
    "            P_r(a)*P_r(b/a) = P_r(b)*P_r(a/b)\n",
    "    \n",
    "        \n",
    "                    P_r(b)*P_r(a/b)\n",
    "        P_r(b/a) = ----------------- }--> this is called as entire fonda of\n",
    "                         P_r(a)           \"Naive_Bayes\" Algorithem. this is\n",
    "                                           called as \"Bayes Theorem\"\n",
    "                   \n",
    "        EX :=              \n",
    "           step 1 :Pr(w) =  3/5\n",
    "            \n",
    "           step 2 :Pr(o) = 2/4 = 1/2 -->0.6* 0.5 = 0.3\n",
    "            \n",
    "           step 3 :Pr(o) = 2/5\n",
    "            \n",
    "           step 4 :Pr(w) = 3/4 =---> 0.4 * 0.75 = 0.3\n",
    " \n",
    "how this Probability apply in our ML algorithems ?\n",
    "            \n",
    "lets take a ML dataset like below\n",
    "\n",
    "      independet features    dependent feature\n",
    "    -----------|-----------       ---|---\n",
    "     x1 , x2 , x3 ......xn           y\n",
    "        \n",
    "        here \"independet\" and \"dependent\" features are \"Correlatd\" b-coz\n",
    "        based on \"independet\" feature chaneges than \"Dependent\" feature \n",
    "        Ouput Changes right\n",
    "          so think \"Naive_Bayes\" will work for this thinks\n",
    "        \n",
    "        Now with respect \"Machine Learning\" alrgm if i have dataset like\n",
    "        \"independent\" and \"dependent\" feature then my \"formula\" looks like\n",
    "        \n",
    "        to converting \"bayes theorem\"\n",
    "        \n",
    "                                P_r(y)*P_r(x1,x2,x3...xn/y)\n",
    "        P_r(y/x1,x2,x3...xn) = -----------------------------\n",
    "                                   P_r(x1,x2,x3...xn)\n",
    "            \n",
    "            \n",
    "            here  :. y is nothing but \"Dependent_feature\" and\n",
    "                  :. x1,x2,x3...xn are \"independet_features\"\n",
    "            \n",
    "                              by \"expanding\" this equation \n",
    "                \n",
    "                                P_r(y)*P_r(x1/y)*P_r(x2/y)...P_r(xn/y)\n",
    "        P_r(y/x1,x2,x3...xn) = ---------------------------------------\n",
    "                                P_r(x1)*P_r(x2)*P_r(x3)...*P_r(xn) \n",
    "            \n",
    "            \n",
    "let say i have \"binary dataset\" \n",
    "\n",
    "     x1 , x2 , x3     y-opt\n",
    "                       yes\n",
    "                       no\n",
    "            \n",
    "    \n",
    "    here concider y = yes  n = no\n",
    "    now my model will predcting\n",
    "    \n",
    "    P_r(y=yes/xi) xi= x1,x2,x3...\n",
    "    \n",
    "    P_r(x1,x2,x3,x4/yes) by expanding this\n",
    "    \n",
    "                    P_r(yes)*P_r(x1/yes)*P_r(x2/yes)*P_r(x3/yes)\n",
    "    P_r(y=yes/xi) = --------------------------------------------\n",
    "                              P_r(x1)*P_r(x2)*P_r(x3) #cancell this\n",
    "        \n",
    "    P_r(y=No/xi)   \n",
    "    \n",
    "                    P_r(No)*P_r(x1/No)*P_r(x2/No)*P_r(x3/No)\n",
    "    P_r(y=No/xi) = ------------------------------------------\n",
    "                              P_r(x1)*P_r(x2)*P_r(x3) \n",
    "        \n",
    "        \n",
    "    \n",
    "    for both the equation p_r(yes and no) the \"denominater\" is same \n",
    "    so \"ignore\" that\n",
    "    \n",
    "Now how the final calculation will happens ?\n",
    "\n",
    "    \n",
    "lets say after doing all calculations  \n",
    "\n",
    "                    P_r(yes/xi) = 0.13 \n",
    "                    P_r(No/xi)  = 0.05 \n",
    "        \n",
    "        \n",
    "    if convert this P_r(yes/xi) into 100% \n",
    "    \n",
    "                             0.13        0.13            }\n",
    "           P_r(yes/xi) = ------------ = ------- = 72%    }----|\n",
    "                         0.13 + 0.05     0.18            }    |\n",
    "                                                              |  if i add\n",
    "                if it is P_r(yes/xi) >= 50 it belongs 1       |  this 2 %`s \n",
    "                                                              |--  \n",
    "         similarly :=                                         | 72+28 = 100%\n",
    "                                                              |\n",
    "                            0.05         0.05           }     |\n",
    "           P_r(No/xi)  = ------------ = ------- = 28%   }-----|\n",
    "                         0.05 + 0.13     0.18  \n",
    "            \n",
    "            }\n",
    "            \n",
    "            if  P_r(yes/xi) >= 50% i say it belongs 1\n",
    "            \n",
    "        similarly\n",
    "        \n",
    "            if  P_r(NO/xi) < 50% i say it belongs 0\n",
    "            \n",
    "        \n",
    "Some example : = with respect to all\n",
    "    \n",
    "                input/independent features            dependent/output feature\n",
    "                          |                                  |\n",
    "--------------------------|---------------------------| -----|-------|       \n",
    "day   |  outlook   |  temperature | humanity | wind   | play_tennies |\n",
    "------|------------|--------------|----------|--------|--------------|\n",
    "d1       sunny          hot          high      weak        no\n",
    "d2       sunny          hot          high      strong      no\n",
    "d3       overcast       hot          high      weak        yes\n",
    "d4       rain           mild         high      weak        yes\n",
    "d5       rain           cool         normal    weak        yes \n",
    "d6       rain           cool         normal    strong      no\n",
    "d7       overcast       cool         normal    strong      yes\n",
    "d8       sunny          mild         high      weak        no\n",
    "d9       sunny          cool         normal    weak        yes\n",
    "d10      rain           mild         normal    weak        yes\n",
    "d11      sunny          mild         normal    strong      yes\n",
    "d12      overcast       mild         high      strong      yes\n",
    "d13      overcast       hot          normal    weak        yes \n",
    "d14      rain           mild         high      strong      no\n",
    "\n",
    "\n",
    "\n",
    "by seeeing this dataset its kinda classification problem b-coz\n",
    "it having fixed number of categories like(\"no\" , \"yes\")\n",
    "if it has 2 categories then it becomes \"binari_class_classification\"\n",
    "if it has more then 2 categories then it becomes \"Multy_class_classification\"\n",
    "\n",
    "problem statement is based on the \"input feature\" the person\n",
    "is going to \"play_tennies\"/play tomarrow or not ? \n",
    "\n",
    "solve this by using \"Naive_Bayes\" algorithem\n",
    "\n",
    "\n",
    "take \"feature\" from dataset like \"outlook\" feature\n",
    "\n",
    "\n",
    "          yes   no   \n",
    "sunny  --  2     3     P_r(yes) = 2/9  |  P_r(no) = 3/5\n",
    "    \n",
    "overcast-- 4     0     P_r(yes) = 4/9  |  P_r(no) = 0/5 = 0\n",
    "  \n",
    "rain    -- 3     2     P_r(yes) = 3/9  |  P_r(no) = 2/5 \n",
    "        ------------\n",
    "           9     5\n",
    "        \n",
    "        i can alos write/say P_r(yes) = 2/9 is nothing but\n",
    "        \n",
    "        P_r(sunny/yes)    = 2/9 similarly\n",
    "        P_r(overcast/yes) = 4/9\n",
    "        P_r(rain/yes)     = 3/9\n",
    "        \n",
    "        similarly with \"no\" aslo i can say it has \n",
    "        \n",
    "        P_r(sunny/no)    = 3/5\n",
    "        P_r(overcast/no) = 0/5\n",
    "        P_r(rain/no)     = 2/5\n",
    "        \n",
    "                \n",
    "take feature anothe feature like \"temperature\"\n",
    "\n",
    "       yes       no     P_r(yes)   P_r(no)\n",
    "hot     2         2      2/9        2/5\n",
    "\n",
    "mild    4         2      4/9        2/5\n",
    "\n",
    "cool    3         1      3/9        1/5\n",
    "      -----------------\n",
    "       9          5\n",
    "  \n",
    "if i go with final o/p feature  \"play_tennies\"\n",
    "\n",
    "take feature like \"play_tennies\"  \n",
    "\n",
    "yes  9     P_r(yes) = 9/14\n",
    "\n",
    "no   5     P_r(no)  = 5/14 \n",
    "   -----\n",
    "    14 \n",
    "    \n",
    "   problem stment  \n",
    "\n",
    "let say tomorrow i get a dataset  where my \"outlook\" is \"sunny\" \n",
    "and my \"temperature\" is \"hot\" i need to predict whether the person\n",
    "is play or not,solve using \"Naive_Bayes\"\n",
    "\n",
    "remember this \n",
    "                    P_r(b)*P_r(a/b)\n",
    "        P_r(b/a) = ----------------- \n",
    "                         P_r(a) \n",
    "            \n",
    "                       P_r(yes) *P_r((sunny,hot)/yes)\n",
    "P_r(yes/(sunny,hot))= -------------------------------- \n",
    "                           P_r(sunny,hot)\n",
    "\n",
    "\n",
    "                       P_r(yes) *P_r(sunny/yes)*P_r(hot/yes)\n",
    "P_r(yes/(sunny,hot))= -------------------------------------- = \n",
    "                           P_r(sunny)*P_r(hot)  #cancel this = its constant \n",
    "    \n",
    "                     = (9/14)*(2/9)*(2/9)\n",
    "        \n",
    "P_r(yes/(sunny,hot)) = (2/63) = 0.031\n",
    "            \n",
    "                       P_r(No) *P_r(sunny/No)*P_r(hot/No)\n",
    "P_r(No/(sunny,hot))= --------------------------------------\n",
    "                           P_r(sunny)*P_r(hot) #cancel this =its constant \n",
    "    \n",
    "                    = (5/14)*(3/5)*(2/5)\n",
    "        \n",
    "P_r(No/(sunny,hot)) = 3/35 = 0.08571\n",
    "\n",
    "            \n",
    " \n",
    "lets caluculate the \"Real_Probabulity\" out of 100\n",
    "\n",
    "                             0.031          0.031\n",
    "  P_r(yes/(sunny,hot)) =---------------- =  ------- = 0.2656 = 26%\n",
    "                          0.031 + 0.08571   0.11671\n",
    "    \n",
    "    P_r(yes/(sunny,hot)) >= 50% it belongs 1\n",
    "    \n",
    "    P_r(yes/(sunny,hot)) < 50% it belongs 0 -->\"this satisfying in yes\"\n",
    "    \n",
    "    so here                                 (0) not go to play\n",
    "                                             (1) = go to play\n",
    "        \n",
    "    \n",
    "    \n",
    "    P_r(no/(sunny,hot)) = 1 - 0.2656 = 0.7343 = 73% and (0) not go\n",
    "    \n",
    "\n",
    "    \n",
    "    going to play b-coz the claimate is \"hot\" & \"sunny\" not good\n",
    "    \n",
    "    why i am doing 1 - \"ouput\" means its \"binary classification\"\n",
    "    b-coz in total 1 if one is 73% then obviously othen one will \n",
    "    be 27% right so it become = 100%\n",
    "    \n",
    " \n",
    "                        0.08571            0.08571\n",
    "  P_r(No/(sunny,hot)) ----------------- = -------- = 0.7343 = 73%\n",
    "                       0.08571 + 0.031     0.11671\n",
    "    \n",
    "     P_r(NO/(sunny,hot)) >= 50% it belongs 0 \n",
    "    \n",
    "     P_r(NO/(sunny,hot)) < 50% it belongs 1\n",
    "        \n",
    "    so from yes and NO observations person not going to \"play\" tommorow\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "if your claimate is \"overcast\" and \"cool\" \n",
    "\n",
    "                        P_r(yes) *P_r(overcat/yes)*P_r(cool/yes)\n",
    "P_r(yes/(overcat,cool))= --------------------------------------  \n",
    "                           P_r(overcat)*P_r(cool) #cancel this \n",
    "    \n",
    "                      = 9/14*4/9*3/9 \n",
    "                      =0.09523 \n",
    "            \n",
    "                         P_r(No) *P_r(overcat/No)*P_r(cool/No)\n",
    "P_r(No/(overcat,cool))= --------------------------------------  \n",
    "                          P_r(overcat)*P_r(cool) #cancel this      \n",
    "                     \n",
    "                      =5/14*0/5*1/5\n",
    "                      =0.0\n",
    "                \n",
    "lets caluculate the real probabulity out of 100\n",
    "                             0.09523           0.09523\n",
    "  P_r(yes/(overcat,cool)) =---------------- =  ------- = 0 = 100%\n",
    "                            0.09523 + 0.0       0.09523   \n",
    "    \n",
    "                                             (0) = not go to play\n",
    "                                             (1) = go to play\n",
    "       \n",
    "                                          \n",
    "        P_r(yes/(overcat,cool)) > = 50% concide as 1 --> \"this satisfy\"\n",
    "        P_r(yes/(overcat,cool)) < 50% concide as 0 \n",
    "        \n",
    "        by seeing this the person is going to play tomorow\n",
    "        \n",
    "    \n",
    "                             0.0             0.0\n",
    "  P_r(yes/(overcat,cool)) =------------ =  -------- = 0.0 \n",
    "                          0.09523 + 0.0    0.09523 \n",
    "    \n",
    "        P_r(NO/(overcat,cool)) > = 50% concide as 1 \n",
    "        P_r(NO/(overcat,cool)) < 50% concide as 0  --> \"this satisfy\"\n",
    "        \n",
    "        remember if he not going to ply % will \"high\"\n",
    "        if he going to play % will \"low\" then 50%\n",
    "    \n",
    "    \n",
    "         1-1.0 = 0.0  the person is going to play \n",
    "    \n",
    "similarly\n",
    "\n",
    "if your claimate is \"overcast\" and \"cool\" \n",
    "\n",
    "                        P_r(yes) *P_r(rain/yes)*P_r(hot/yes)\n",
    "P_r(yes/(rain,hot))= --------------------------------------  \n",
    "                           P_r(rain)*P_r(hot) #cancel this \n",
    "    \n",
    "                      = (9/14)*(3/9)*(2/9 )\n",
    "                      = 0.04761\n",
    "            \n",
    "                         P_r(No) *P_r(rain/No)*P_r(hot/No)\n",
    "P_r(No/(rain,hot))= --------------------------------------  \n",
    "                          P_r(rain)*P_r(hot) #cancel this      \n",
    "                     \n",
    "                      =(5/14)*(2/5)*(2/5)\n",
    "                      =0.057142\n",
    "                \n",
    "lets caluculate the \"real probabulity\" out of 100\n",
    "\n",
    "                                0.04761          \n",
    "     P_r(yes/(rain,hot)) =------------------- =  0.45454 = 45%\n",
    "                            0.04761 + 0.057142       \n",
    "    \n",
    "    \n",
    "        P_r(yes/(rain,hot)) > = 50% concide as 1 \n",
    "        P_r(yes/(rain,hot)) < 50% concide as 0 --> \"this satisfy\"\n",
    "        \n",
    "        remember if he not going to ply % will \"high\"\n",
    "        if he going to play % will \"low\" then 50%\n",
    "        \n",
    "        1-0.45454 = 0.5454 = 54% he is not go\n",
    "        \n",
    "        \n",
    "                                             (0) = not go to play\n",
    "                                             (1) = go to play\n",
    "                              0.057142          \n",
    "     P_r(NO/(rain,hot)) =------------------- =  0.54545 = 54\n",
    "                            0.04761 + 0.057142 \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175546ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87828a20",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    lets see how croos validation works\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "Cross Validation :=\n",
    "\n",
    "when we use Cross_validation Technich ?\n",
    "\n",
    "Ans :=Cross Validation happens only on \"Training_data\" we do this\n",
    "    if we have to seperate \"Test_data\" or \"Validation_data\" form\n",
    "    entire dataset,\n",
    "    so when we have \"huze amount of data\" we usually apply\n",
    "    \"Cross_validation\" on \"Training_data\"\n",
    "    as we keep on increasing \"Cross_validation\" value so that the\n",
    "    Model \"Training\" \"time\" will also \"increase\"\n",
    "    \n",
    "    over hare we \"Travercing\" ,with respect to \"Train\" and \"Test\" \n",
    "    from \"starting\" to till the \"ending\" so that it will give me a\n",
    "    \"Generalized_model\" which is nothing but \"low Bias\" and \"low_Variance\"\n",
    "    \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score :=\n",
    "    bassically \"cross_val_score\" what it does is it will do \n",
    "    \"Cross_validation\" and  internally it will apply \"Machin_Learning\"\n",
    "    Algorithem and it will also give you the \"Accuracy\"\n",
    "\n",
    "    \n",
    "  \n",
    "lets say i have 1000 datapoints \n",
    "\n",
    "   x1   x2   x3   x4        o/p\n",
    "    \n",
    "   --\n",
    "   -- \n",
    "   -- \n",
    "\n",
    "Cross Validation :=\n",
    "    \n",
    "    let say i have 1000 data_points in my entire Dataset\n",
    "    \n",
    "    when we need to Train our model we \\ need \"Train_data\" and\n",
    "    \"Test_data\"\n",
    "    so that i can Convert this Entire Dataset int {\"Train\",\"Test\" split}\n",
    "    this is one way. means like 70% data \"Train_data\" 30% data \"Test_data\".\n",
    "    for this we use \"train_test_split\"\n",
    "    \n",
    "\n",
    "the another way of spilt data i do 5 different types of \"Cross_validation\"\n",
    "    \n",
    "    let say in my \"Train_data\" i want 70% of the data.\n",
    "        and in my \"Test_data\" i want 30% of the data. \n",
    "        \n",
    "so out of these 1000 \"data_points\" how many data_points \n",
    "will present in the 70% of the \"Train_data\"\n",
    "        \n",
    "Ans := 700 data_points (1000*0.70) in \"Train_data\"\n",
    "           \n",
    "    and similarly \"Test_data\" will be 300 (1000*0.30).\n",
    "        \n",
    "now if i say my \"Cross_validation\" is = 5\n",
    "\n",
    "i want to iterate(itarate) through all my dataset with in this\n",
    "\"Cross_validation\" as 5\n",
    "\n",
    "with respect to my \"Cross_validation\" 5 \n",
    "\n",
    "  \n",
    "  |-------------------------|  }- >concider this total is                        \n",
    "  |-------------------------|  }   \"entire dataset\" \n",
    "\n",
    "    \n",
    "    \n",
    "           Train_data\n",
    "  |-----|--------------------|  this is my \"Cross_validation\" = 1     \n",
    "  |-----|--------------------| \n",
    "    Test                                                 \n",
    "         Train_data        \n",
    "     ------|------       \n",
    "     |    200    |        \n",
    "  |-----|-----|---------------|\n",
    "  |-----|-----|---------------| this is my \"Cross_validation\" = 2\n",
    "          Test\n",
    "        \n",
    "  |-----------|-----|---------|\n",
    "  |-----------|-----|---------| this is my \"Cross_validation\" = 3\n",
    "    Train_data  Test \n",
    "        \n",
    "  |-----------------|-----|----|\n",
    "  |-----------------|-----|----| this is my \"Cross_validation\" = 4\n",
    "     Train_data       Test\n",
    "        \n",
    "  |-----------------------|----|\n",
    "  |-----------------------|----| this is my \"Cross_validation\" = 5\n",
    "       Train_data          Test\n",
    "          \n",
    "    \n",
    "    now if i divide 1000/5 = 200 here 1000 = \"data_points\" \n",
    "                                         5 = \"Cross_validation\"\n",
    "        \n",
    "    lets concider this 200 as my \"Test_data\"\n",
    "    \n",
    "    so when start \"Cross_validation\" = 1 the starting 200 records\n",
    "    will be my \"Test_data\" and remaining all 800 will be \"Train_data\"\n",
    "    then with my Model i get my \"Accuracy\"\n",
    "    \n",
    "    similarly with \"Cross_validation\" = 2 then next 200 records will\n",
    "    be my \"Test_data\"  and remaining all 800 will be \"Train_data\"\n",
    "    \n",
    "    similarly : \"Cross_validation\" = 3\n",
    "                \"Cross_validation\" = 4\n",
    "                \"Cross_validation\" = 5\n",
    "                \n",
    "    So we get different different \"Acuuracy\", b-coz my \"Train\" & \"Test\" \n",
    "    data getting changed with respect different \"Cross_validation\"`s\n",
    "        \n",
    "    then at the End ofthe day if i findout \"Avarage\" of all \"Accuracy\"\n",
    "    will get a \"Better Model\" by compare to 1 to 1,\n",
    "        \n",
    "    see over hare we \"Travercing\" ,with respect to \"Train\" and \"Test\" \n",
    "    from \"starting\" to till the \"ending\" so that it will give me a\n",
    "    \"Generalized_model\" which is nothing but \"low Bias\" and \"low_Variance\"\n",
    "        NOTE :=\n",
    "            \n",
    "    \n",
    "    this \"Cross_validation\" usually happens only in \"Traing_data\" we do this.\n",
    "        \n",
    "    if we have a saparate \"Tsting_Data\" or \"Validation_data\" for \n",
    "    those data we only \"Validate\" or we only do the \"Prediction\"\n",
    "        \n",
    "    so when we have \"huze amount of data\" we usually apply\n",
    "    \"Cross_validation\" on \"Training_data\"\n",
    "        \n",
    "    \"Cross_validation\" value can be different it can 5 or 10 somthing\n",
    "    we can use \"hyper parameter\" for \"Cross_validation\" also \n",
    "    \n",
    "    as we keep on increasing \"Cross_validation\" value so that the\n",
    "    Model \"Training\" \"time\" will also \"increase\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e6911",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN where used?\n",
    "\n",
    "Ans:-\n",
    "    finnace\n",
    "    handwritting detection\n",
    "    image recognition\n",
    "    video rcognition\n",
    "    pattern rcognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403c9f5f",
   "metadata": {},
   "source": [
    "# KNN Algorithem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d36567e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    |     •  •\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "(K_Nearest_Neighbour) KNN algorithem :=\n",
    "    \n",
    "    'K Nearest Neighbour' can be use solve both \"Classification\" and \n",
    "    \"regression\" problem , \"K\" represents number of \"Neighbour\" and \n",
    "    its \"Distance based\" Algorithem\n",
    "    \n",
    "    let say i have a dataset related to \"Binary classification\"\n",
    "    \n",
    "                      [:. \"K\" represents number of \"Neighbours\"]\n",
    "       |     •  •       \n",
    "       |   • • • •  🔸   \n",
    "       |   • • •     * * *         🔸---> new test_data\n",
    "       |  • •      *  *  *          • ----> category/output 1 \n",
    "       |  •      * * *  *           * ----> category/output 2   \n",
    "       |        *   *  *\n",
    "     --|---------------   \n",
    "       |     \n",
    "    sopose this is my entire \"Training data\" with 2 Categories\n",
    "    \n",
    "with respect to new \"test_data\" we need to determine whether this\n",
    "\"test_data\" is belongs to \"output feature\" 1 or \"output feature\" 2\n",
    "\n",
    "what does \"K_Nearest_Neighbour\"(KNN) will do ?\n",
    " it try to \"find out\" the distance with respect to nearest\n",
    "\"K_Neighbour\",\n",
    "\n",
    "lets say K=5 \n",
    "\n",
    " so its goning  check 5 nearest 5 \"Neighbors distance\"\n",
    "    so where is the maximum \"Nearest Neighbours\" its going \n",
    "    to choose that or its belong to that ,\n",
    "    \n",
    "we need to find out 'K' value with the help of \"hyper_parameter Tuning\" \n",
    "like how it does is with the help of \"GridSearchCV\", \n",
    "\n",
    "but always know \"K\" will always be a \"odd\" number if it\n",
    "become \"even\" number in that case it may becomr \"tie\" so it\n",
    "dont know which category need to choose , \n",
    "\n",
    "\n",
    "how is this distance calculated ?\n",
    "\n",
    "  there is 2 types to \"calculation\" to find out \"distance\" \n",
    "   \n",
    "    1. Eucledian Distance\n",
    "    2. Manhattan Distance\n",
    "    \n",
    "    \n",
    "1. Eucledian Distance  :=\n",
    "    lets say i have 2 points\n",
    "    \n",
    "                  🔷(x2,y2)\n",
    "                  /|y2\n",
    " we need this    / | \n",
    " distance <-----/  |\n",
    "               /   |      \n",
    "              /    |\n",
    "             /     |\n",
    "     (x1,y1)🔷____|y1\n",
    "           x1      x2\n",
    "    \n",
    "if i need to calculate the distance B/W 2 points\n",
    "    \n",
    "    we calculating this distance with the help of \"pythogorus theorem\",\n",
    "    connect this i make up this as like\n",
    "    \n",
    "                    √ (x2-x1)²+(y2-y1)²\n",
    "    \n",
    "    lets say if suppose i have 3 points\n",
    "    \n",
    "                       🔷(x2,y2,z2)\n",
    "    \n",
    "    \n",
    "    (x1,y1,z1)🔷  \n",
    "                    \n",
    "        \n",
    "        now here my \"formula\" like this\n",
    "    \n",
    "                         √ (x2-x1)²+(y2-y1)²+(z2-z1)²\n",
    "        \n",
    "      so here as we keep on \"incresing\" the number of \"dimensions\"\n",
    "my \"formula\" will also be \"increse\" with respect to \"dimensions\"\n",
    "\n",
    "\n",
    " Example:=       \n",
    "  Note :=\n",
    "    flight navigator probably uses \"Eucledian Distance\"\n",
    "        \n",
    "\n",
    "2. Manhattan Distance :=\n",
    "     \"Manhattan Distance\" calulate the opposite side of \n",
    "     \"Eucledian Distance\" points  \n",
    "    \n",
    "                      \n",
    "                     /*these are my \"2 points\" here point_1 \n",
    "                    / |\n",
    "                   /  |\n",
    "                  /   | \n",
    "                 /    | ^\n",
    "                /     | |2nd we       \n",
    "               /      | |calulate this \n",
    "              /       | |distance in this\n",
    "             /        | | \"direction\"\n",
    "            /         | |\n",
    "           /          |\n",
    "   point_2*-----------|\n",
    "           -------> \n",
    "         1st we calculate\n",
    "        this distance in\n",
    "        direction\n",
    "    \n",
    "       for this formula is  |(x2-x1) + (y2-y1)|\n",
    "        \n",
    "        \n",
    "  Example :=\n",
    "     Note :=\n",
    "    spider man will fly/jump like probably uses \"Manhattan Distance\"\n",
    "    \n",
    "how can we solve KNN with Regreson ?\n",
    "    \n",
    "\"K_Nearest_Neighbour\"(KNN) in case of \"Regression\" :=\n",
    "    \n",
    "    let sat i have data point like this\n",
    "                                 \n",
    "       |       * *               :. see Regression means continous so that\n",
    "       |   *  * *  * *              datapoints will be same mind think...\n",
    "       |   **   🔸 * * *         \n",
    "       |  *   * *  *  *           🔸---> new data_point\n",
    "       |  * * *   * * *  *        * ----> data_points  \n",
    "       |        *   *  *\n",
    "     --|--------------- \n",
    "    \n",
    "     \n",
    "if my K = 5 this will find out by \"hyperparameter tunning\"\n",
    "    \n",
    "i find out which \"data_point\" that is near to my \"new_data\" point\n",
    "if my K=5 then it search for 5 Nearest \"data_points\" and then\n",
    "i will try to find out the \"Avarage\" of all this points and that\n",
    "will be the output,\n",
    "\n",
    "but here we will use  \"Mean_Squared_Error\"[MSE] as \"loss_function\",\n",
    "\"Mean_Squared_Error\"[MSE] for just to check the \"Metrix\" \n",
    "\n",
    "\n",
    " \n",
    "IMP {QI}\n",
    "how do we select my \"K\" value ?\n",
    "ans:=\n",
    "    suppose i have 2 groups of \"data_points\"\n",
    "    \n",
    "       |     •  •       \n",
    "       |   • • • •  🔸   \n",
    "       |   • • •     * * *         🔸---> new 'test_data'\n",
    "       |  • •      *  *  *          • ----> \"data_points\" 1 \n",
    "       |  •      * * *  *           * ----> \"data_points\" 2   \n",
    "       |        *   *  *\n",
    "     --|------------------->   \n",
    "       |  \n",
    "    \n",
    "    now i will start check with K=1\n",
    "    \n",
    " if \"K\"=1 that bassically means it checkout(distanse) \"Nearest\" \n",
    "\"data_point\"\n",
    "   So now with respect \"K\"= 1 we find out the \"Accuracy\"  |\n",
    "                       \"K\"= 2 we find out the \"Accuracy\"  |\n",
    "                       \"K\"= 3 we find out the \"Accuracy\"  |\n",
    "             similary    :                                |\n",
    "                         :                                V\n",
    "                         :  as we play with K value ahead the \"Accuracy\" will\n",
    "                         :   \"increase\"/\"better\"\n",
    "                            \n",
    "    but when we go ahead and take more \"K\" values, we will\n",
    "    be this kind of \"graph\" with respect to the \"Error\"\n",
    "       ^\n",
    "       |\n",
    "       |*          \n",
    "       |*   \n",
    "       | *         \n",
    "       |   *             \n",
    "       |     *            \n",
    "       |       *  *  *   *  *     and finally when we see that this\n",
    "     --|-------✦-----------------> \"graph\" going to \"stable\" \n",
    "       |       \"K\"|                 that \"K\" value we will try\n",
    "                  |                to take, but \"K\" should be \"odd\"\n",
    "                  |\n",
    "                  |\n",
    "                  at these case \"Accuracy\" will be preety\n",
    "                    much \"Better\" and it will \"Stable\".\n",
    "                    \n",
    "                    \n",
    "    Voting in \"Classififation\" is done based on \"Majority of the Votes\"\n",
    "    Example :- \n",
    "        if have 0,0,1,1,1 outputs like this so here \"Mejority Vote classifier\"\n",
    "        will concider output as 1, b-coz 1 is most freqquent.\n",
    "        \n",
    "    but KNN :=\n",
    "        maximum neibhours where ever it present its gonig to take that.\n",
    "        \n",
    "        \n",
    "-------------------------------------------------------------\n",
    "                    \n",
    "Sunny extra topics on KNN :=\n",
    "    \n",
    "  let say my data set like\n",
    "\n",
    "       |     •  •       \n",
    "       |   • • • •  🔸   \n",
    "       |   • • •     * * *         🔸---> new 'test_data' 5\n",
    "       |  • •      *  *  *          • ----> \"data_points\" 1 \n",
    "       |  •      * * *  *           * ----> \"data_points\" 2   \n",
    "       |        *   *  *\n",
    "     --|------------------->   \n",
    "       |  \n",
    "        \n",
    "        if my \"K\" = 5 then i choose 5 \"nearest neighbors\"/\"Distance\"\n",
    "        \n",
    "if my 3 point belongs to \"data_points\" 1 • } if i need to come to the \"conclusion\"\n",
    "if my 2 point belongs to \"data_points\" 2 * } like 3 poins form this 2 points that\n",
    "                                            so that  need to calculate entire \n",
    "                                            \"Datapoints\" means from each and every\n",
    "                                           point we need to \"calculate\", thats how\n",
    "                                           we come to \"conclusion\"\n",
    "    Note : here \"Probability\" also comes into\n",
    "        picture over here, but we calculate the \"probability\"\n",
    "        at the last\n",
    "        \n",
    "        here we have to calculate \"Class_probability\"\n",
    "        \n",
    "    let say if my \"dataset\" having 1000 poins in that 5 \"points\" are \n",
    "    \"nearest neighbours\"/\"distance\" in that 5 points \n",
    "     3 point belongs to \"dataset_points\" 1 • \n",
    "     2 point belongs to \"dataset_points\" 2 *\n",
    "                [:. we choose 3 b-coz which has high points that we choose]\n",
    "        \n",
    "    so the \"probability\" will be choosen like \n",
    "                \n",
    "                see picking up from 5 is happen like 3/5 and 2/5 \n",
    "               so similarly which is having high probability \n",
    "                that we can choose\n",
    "                     3          2\n",
    "                    ----  >   -----    3/5 if greater then 2/5\n",
    "                      5         5 \n",
    "                   like this \"Sklearn calculate\" the \"probability\" \n",
    "                in a \"back end\"\n",
    "                \n",
    "    my data set like \n",
    "    \n",
    "    we are \"calculating\" distances like with respect to \n",
    "    (1000) data points ---> performance betrer\n",
    "    (100000) data points\n",
    "    (1000000) data points\n",
    "    \n",
    "so can we \"reduse\" this thing(datapoints) so my performance will be a better ? \n",
    "yes we can \"reduce\" the data points so that our performance will be good \n",
    "so that thay have \"saggested\" some \"method\"\n",
    "    so we can do some \"Optimisation\" over here not in turms of \n",
    "    \"machine learning\", this is the \"hard technique\"\n",
    "    \n",
    "    we are Reduse some datapoints like\n",
    "     \n",
    "        1000 datapoint ---to selct---> 5 nearest neighburs\n",
    "            but we are going to do it \"Reduse\" like 500 data points\n",
    "            to fnd out the 5 \"nearest neighburs\", thats it\n",
    "            like this i have to \"segregate\"/reduse my data,\n",
    "            \n",
    "    for \"segregation\"/\"Reduce\" of \"dataset\" there are \"some methods\"\n",
    "    \n",
    "    we can use \"Tree_data\" \"Structure\" for \"Aranging\" of a \"data\"\n",
    "    \n",
    "    what is \"Data Structure\" defination ?\n",
    "    \n",
    "    Ans := we are going to \"Arange\" data in a \"best\" and \"Possible\" \n",
    "           way\n",
    "    \n",
    "    \n",
    "    so we create \"Tree_data\" strcture,  suppoese i heve 1000 \"data points\"\n",
    "   in Tree_data strcture you dont need to \n",
    "   \"traverse\" entire data \n",
    "    \n",
    "         〇              soppose my \"dataset\" diveded into these \"Tree\" strcture\n",
    "         / \\             let say it has 6 \"child_nodes\" with recpect to our dataset,\n",
    "        /   \\ > \\        from my dataset 3 points are choosen(\"nearest nebours\")\n",
    "      </     \\   \\       where its \"greter\" its like go there see here we are \n",
    "      /       \\          \"not traverce\" the \"entire\" dataset, \n",
    "     /         \\         So like our \"dataset\" is divided to \"Traverce\"as little\n",
    "    ◯          ◯       as possible, that how we get a \"Better performance\" \n",
    "<  /  \\ <    < /  \\ >     \n",
    " ◯    ◯     ◯   ◯ <--like here we \"reach\"    \n",
    "    \n",
    "    \n",
    "    Algorithem saggested fot that\n",
    "    \n",
    "    1.\"K-d Tree\"   2.\"Ball Tree\"  3.\"Brute force\"\n",
    "    \n",
    " 1.\"K-d Tree\"  \n",
    "\n",
    "let say my dataset with some \"independent\" and \"dependent\" features (x,y)\n",
    "\n",
    "   independent --> x\n",
    "   dependent ---> y\n",
    "       x-axis\n",
    "       y-axis concide\n",
    " x , y  \n",
    "(1   2)     (1 ,2)  (2 , 3) (2, 4)   (3, 6) (4 , 2)  (5 , 7)  \n",
    "(2   3)        \n",
    "(2   4)     (6 , 8) (7  ,5) (8 , 5) (9,  1) (9 , 3)  \n",
    "(3   6)\n",
    "(4   2) \n",
    "(5   7)    x- axis -> 1 2 3 4 5 6 7 8 9 9  based on this data we are \n",
    "(6   8)                                    going to \"segregae\"/\"reduse\" \n",
    "(7   5)                                     \n",
    "(8   5)    for \"segregating\"/\"reducing\" data we have \"Sort\" the data 1st\n",
    "(9   1)   \n",
    "(9   3)       So sorted data will :-  1 2 3 4 5 6 7 8 9 9\n",
    "            take \"mean\" or \"median\" of it we generally take \"Median\"\n",
    "(10,4)        \n",
    "            \"Mean\" = (1+2+2+3+4+5+6+7+8+9+9) / 10  = 5.6\n",
    "         \n",
    "            \"Median\"= 5\n",
    "            \n",
    "            \n",
    "               |---------|---|-----------| \n",
    "               |1 2 2 3 4| 5 | 6 7 8 9 9 |  lets concide \"Median\" as 5\n",
    "               |---------|---|-----------|\n",
    "       <-------------         -----------> this things \"Right-hand\" side\n",
    "this go \"left-hand\"side    \n",
    "                                         so along with 5 you have \"y-axis\"\n",
    "                                        data point like (5 ,7) \n",
    "            \n",
    "                         (5 ,7) \n",
    "                        /      \\\n",
    "        (2,4)(1 2 |2| 3 4)   (6 7 |8| 9 9)(8,5) check the \"median\" both sides \n",
    "                   |               |           \n",
    "                  / \\             / \\  \n",
    "    lessthen     /   \\           /   \\   greate then values\n",
    "                /     \\         /     \\         \n",
    "             |1 2|    |3 4|  |6 7|   |9 9| \n",
    "                    \n",
    "                    \n",
    "                    so finaly the \"Tree dataset\" create like this\n",
    "                    \n",
    "  (1 ,2)  (2 , 3) (2, 4)   (3, 6) (4 , 2)  (5 , 7)\n",
    "  (6 , 8) (7  ,5) (8 , 5) (9,  1) (9 , 3)\n",
    "    \n",
    "now i have \"new point\"\n",
    "10 with respect x \n",
    "                     10>5(5 ,7)      here we have taken \"x\" axis values\n",
    "                        /     \\     based on \"x-axis\" we have define the data\n",
    "                  (2,4)     10>8(8,5) \n",
    "                   |               |        so it will \"reaches\" (9,1) like checkig      \n",
    "                  / \\             / \\      grater then of > 10 \n",
    "                 /   \\           /   \\     10 point with respect to x-axis letsay\n",
    "                /     \\         /     \\         \n",
    "            (2,3)     (3,6)   (7,5)    (9,3)10>9  here we are solving Regression  \n",
    "             / \\        \\        /        \\       problem so we need to calculate \"mean\" \n",
    "            /   \\        \\      /          \\      So now here y values\n",
    "           /     \\        \\    /            \\  \"mean\" = (7+5+3+1)/4 =4.0 its y\n",
    "          /       \\     (4,2) (6,8)          (9,1)10>9\n",
    "        (1,2)   (3,6)               like how \"instead\" of \"checking\"/\"calculating\"\n",
    "                                    all points \"distance\" only in 4 \"steps\"\n",
    "                                    it consider the 4 points \"distanse\" so \n",
    "                                    Obviously the \"Speed\" of the Algorithem\n",
    "                                    will \"increase\"\n",
    "                    \n",
    "                   so finally my (x,y) value is =(10,4)\n",
    "                10 ----> we concider as new datapoint\n",
    "                4 ----> \"mean\" of  \"distances\"/\"target_features\" y\n",
    "                \n",
    "        if my \"K=3\" then i choose \"nearest points\" so (5,7)(8,5)(9,3)(9,1)\n",
    "        in this 4 points if K=3 near to \"each other\", so thos 3 points \"near\"\n",
    "        to 10 that points will get selected in that \"y\" willbe calculated\n",
    "        so points are (8,5)(9,3)(9,1) near to 10 and combined \"each other\"\n",
    "        \n",
    "        \n",
    "        if (K=5) it wont work b-coz we having \"4 points\" only \"this is Example only\"\n",
    "        \n",
    "        so  if K=3 so near to 10, points will be (8,5)(9,3)(9,1) from this\n",
    "        claculate y \"mean\" = 1+3+5/3 =  9/3 = 3\n",
    "        (8,5)(9,3)(9,1)\n",
    "        8  NO\n",
    "        9 YES   } -- megority will be \"NO\"\n",
    "        8 NO                       2                1\n",
    "             so in thi P_r(No) =  ----  ,P_r(YES)= ----\n",
    "                                    3               3 \n",
    "                then use \"probability\" these to you get final yes or no %\n",
    "                    \n",
    "                    \n",
    "what is \"hyper parameter tuning\"  ?\n",
    "\n",
    "Ans:=\n",
    "    \"hyper parameter tuning\" is nothing but over here we just play with the\n",
    "    different different \"hyper parameters\" of the model, means we are having\n",
    "    different different \"hyper parameter\" with respect to different different\n",
    "    \"models\"/\"Algorithems\",\n",
    "    different different \"methods\" for \"hyper parameter\" \n",
    "    1.GridSearchCV\n",
    "    2.RondomSearch\n",
    "    3.Optuna...etc   still here we only doing ModelBuilding\n",
    "    \n",
    "    Evaluation of the Model \n",
    "    \n",
    "    for \"regression\"                \"classification\"\n",
    "          r2_score                   confusion_matrix\n",
    "           Mse                        recall_score\n",
    "           MAE\n",
    "           Adjested R2\n",
    "          \n",
    "confusion_matrix \n",
    "  in this \"confusion_matrix\" we have  TP FP\n",
    "                                      FN TN\n",
    "        \n",
    "    we are going to find out \"TP_Rate\",\"TN_Rate\",\"FP_rate\",\"FN_rate\"\n",
    "    or we are going to find out \"pression\",\"recall\",\"Fbeta_scare\",\n",
    "    \"accuracy\", \"Sensitivity\",\"Specifity\",\"Pr_Curv\",\"roc_auc_curv\"\n",
    "    \n",
    "    \n",
    "    \n",
    " What is \"hyper parameter\" and what is \"model parameter\" ?\n",
    "  Ans : suppose like this alrgm \"K-NN\",\"K-means\",\"K-medoid\"\n",
    "        in this alrgm you need to define that how many \"Nearest neighbor\"\n",
    "        that you want how may \"clusters\" that you want like so in that\n",
    "        we need to \"determine\" it pre defined means before starting\n",
    "        of our Algorithem so these are nothing but the \"hyper parameter\"\n",
    "        \n",
    "        Note :=\n",
    "            \"hyper parameter\" are indeed(నిజానికి) also know as \n",
    "            \"optimization parameters\"\n",
    "        \n",
    " example \"Sopport vector Mahine\" we have turm like \"C\" and \"Eta\"(ξi)\n",
    "         we set Externally,\n",
    "    \n",
    "        if you have a \"model_parameter\" and it is manually set,\n",
    "        if this \"model_parameter\" \"manually\" set then this is called\n",
    "        as \"hyper_parameters\" , \n",
    "        \n",
    "        if you dotn \"manually\" set it then that becomes a \"Model_parameter\"\n",
    "        \n",
    "                    \n",
    "\n",
    "1,Explain \"KNN\" is not mahichine Learning Algorithem ?\n",
    "\n",
    "Ans :=\n",
    "    \"Learning\" is not happening in \"KNN\" and its lasy to learn\n",
    "    Thats why its not a ML \"algorithem\" \n",
    "    with respect to \"KNN\" the \"Self_Optimazation\" is not\n",
    "    happening. we are not having any \"loss_function\" over there\n",
    "    we are just doing what \"Nearest Points\" to the \"K\"\n",
    "    based on that we are caluculating \"distance\", based on\n",
    "    that we are able to evalvate our \"model\"\n",
    "       \n",
    "2,why Linear Regression ML Algorithem ?\n",
    "\n",
    "Ans :=why \"Linear Regression\" ML Algorithem is in the sence\n",
    "    \"Self_Optimazation\" happenig over there so thats why\n",
    "    its called \"Linear Regression\" is ML Algorithem\n",
    "    \n",
    "3,Can we use \"KNN\" for handling missing Values ?\n",
    "\n",
    "Ans := yes we can use \"KNN\" for \"handling missing\" values \n",
    "    how you can handle missing values with \"KNN\" ?\n",
    "    Ans :-\n",
    "        what ever \"missing\"/\"Outliers\" values we were having \n",
    "        we make it has as \"Target\" varible and \"rest\" of the variable\n",
    "        we we make it as a \"Training\" variable\n",
    "        \n",
    "4,Can we give \"large_dataset\" or \"small_dataset\" on which dataset\n",
    "my \"KNN\" is going to work fine ?\n",
    "\n",
    "Ans := \"small_dataset\",  b-coz here we just calculating the \"distance\"\n",
    "       as we are going to increase the size of the \"dataset\" the \n",
    "        space\"complexity\" could be going to be \"increase\" so its \n",
    "        best for the \"small_dataset\"\n",
    "        \n",
    "\n",
    "5, what axactly the \"K\" is indicating  ?\n",
    "\n",
    "Ans := In KKN alrgm \"K\" its indecating \"Nearest Neighbor\"\n",
    "\n",
    "6, can we take K value as  \"odd value\" or \"even value\" ?\n",
    "\n",
    "Ans := \"odd value\" the reson b-coz if we take \"even value\" \n",
    "    there is chance it may \"tie\" so to avoid 'tie' best\n",
    "    to take 'odd_value'\n",
    "    \n",
    "7, how we can deside \"K\" value ?\n",
    "Ans :=\n",
    "    \"K\" is \"hyper parameter\" so we can take different different \n",
    "    values so based on that we get \"Accuracy\" we can deside\n",
    "    \"K\" value\n",
    "    \n",
    "8,can we solve \"Classification\" and \"Regrassion\" problem with KNN?\n",
    "\n",
    "Ans := Yes\n",
    "    \n",
    "9, what is the difference b/w \"Lasy learner\" and \"eager learner\"?\n",
    "\n",
    "Ans := in \"lasy learner\" we \"fitting\" the data, means we are just \n",
    "    giving the data for \"colculation\",\n",
    "    \n",
    "    in \"eager learner\" we \"generalize\" the data with the help of\n",
    "    \"loss_function\" we are going to \"optimize\" with the parameters \n",
    "    \n",
    "    \n",
    "    \n",
    "\"K_Nearest_Neighbour\"(KNN) will be get impacted by \"outliers\" or not ?\n",
    " \n",
    " Ans:=\n",
    "      yes it will get  impacted becoz obviusly if there are\n",
    "      \"outliers\" definatly its gonna get impacted b_coz \"KNN\"\n",
    "      works on\" K Nearest Neibour\", Outliers it not concider\n",
    "      as \"Near\" point\n",
    "        \n",
    "should we do any kinda \"Feaure_scaling\" in \"K_Nearest_Neighbour\"(KNN) ?\n",
    "   \n",
    "  Ans:=\n",
    "    yes for a \"distance based\" alrmgm so we really need to do \"Feaure_scaling\"\n",
    "\n",
    "whether KNN will be get impacted  by \"imbalance\"dataset on not ?\n",
    "\n",
    "  Ans :=\n",
    "        yes\n",
    "        \n",
    "Do we require \"Feature Scaling\" in \"SVM\" ?\n",
    "\n",
    "Ans :=\n",
    "    Yes\n",
    "    \n",
    "Do we requie \"Feature Scaling\" in \"Logistic\" Rgression ?\n",
    "\n",
    "Ans :=\n",
    "    yes we b-coz we queekly rech to the \"Global Minima\" in\n",
    "    \"Gradient Decent\" so that \"Feature Scaling\" is Require\n",
    "    \n",
    "Do we requie \"Feature Scaling\" in \"Linear\" Rgression ?\n",
    "\n",
    "Ans :=\n",
    "    yes we b-coz we queekly rech to the \"Global Minima\" in\n",
    "    \"Gradient Decent\" so that \"Feature Scaling\" is Require\n",
    "        \n",
    "    \n",
    "        \n",
    "#################################################################################\n",
    "                    \n",
    "HOW do you select the Algorithem ?\n",
    "\n",
    "Ans := we have to \"Apply\" each and every \"Algorithem\" and which ever\n",
    "    Algorithem give you the best \"Accuracy\"/\"performance Metrics\" we \n",
    "    can go with that  \n",
    "    or \n",
    "    we have to \"Apply\" each and every \"Algorithem\" whether its a \n",
    "    \"Classification\" problem or \"Regreesion\" problem stmt i have\n",
    "    to check out through all the \"Accuracy\"/\"performance Metrics\"\n",
    "                    \n",
    "                    \n",
    "V.V.IMP IQ (KNN)Standardization \n",
    "what is \"Standardization\" and why we use \"Standardization\" ?\n",
    "\n",
    "Ans:=\n",
    "    we need to \"Standardization\" b-coz the \"KNN\" is \"distance based\"\n",
    "    Algorithem so i have to do the \"Standardization\", why b-coz its\n",
    "    help me to get queekly solve my \"Problem\" stmt\n",
    "    \n",
    "    \n",
    "do we need to Standardize the Target/output feature ?\n",
    "Ans :=\n",
    "    No\n",
    "    why NO ?\n",
    "    ans := it is the output we cant do enything to it \n",
    "           b-coz that same \"output\" we come up with respect\n",
    "            to the \"Model\" output it self\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "what is difference B/W \"fit\" and \"transfrom\" ? in SVM (KNN pR) time2:43\n",
    "Ans : =\n",
    "    \"fit\" is we bassically do for \"Training_dataset\"\n",
    "    \n",
    "    \n",
    "\n",
    "what is the main perpose of StandardScaler?\n",
    "Ans:=\n",
    "    this is basically transforming/changing/standardise the data \n",
    "    that is nothing but we are changing the data\n",
    "    \n",
    "    let say i have features like\n",
    "    \n",
    "                f1     f2  f1-stds    \n",
    "                 2           -1   after \"standardisation\" the \"Train_data\"              \n",
    "Train_dataset    3            0   convert like  this\n",
    "                 4            1  \n",
    "               -------      -------                 \n",
    "Test_dataset     5            2   after \"standardisation\" the \"Test_dataset\"  \n",
    "                 6            3   convert like  this\n",
    "    \n",
    "    with respect to \"Train_dataset\" data set\n",
    "    if i want to do \"standardization\" for f1_feature \n",
    "    the values will like 2,3,4 from \"Train_dataset\"\n",
    "                 \n",
    "                 \n",
    "                 xi- μ       \n",
    "      Z_score = --------   here mean \"μ\" = 2+3+4/3 = 9/3 = 3\n",
    "                   σ \n",
    "        \n",
    "                 f1-\"μ\" \n",
    "                 2 - 3 = -1 \n",
    "                 3 - 3 = 0\n",
    "                 4 - 3 = 1      \n",
    "    \n",
    "    so we need to apply \"fit\" and then \"transform\" we can also apply\n",
    "    \"fit_transform\"\n",
    "    \n",
    "    so finally \"fit\" and \"transform\" and \"fit_transform\" incase of \n",
    "    \"Train_dataset\" it will do standardisation in that the .\n",
    "    \n",
    "    mean(\"μ\") and Standardiviation(\"σ\") will get calculate to standardise\n",
    "    and it will get \"transformed\" for terget/output \"feature\"\n",
    "    \n",
    "    What about the \"Test_data\" ?\n",
    "    \n",
    "    Ans :=  \"Test_dataset\" value are 5,6 here we \"dont again calculate\" the\n",
    "            mean(\"μ\") Standardiviation(\"σ\") we use \"Train_dataset\" mean\n",
    "            only, to Standardize it\n",
    "                5 - 3\n",
    "              -------- = 2  and similarly 6-3 / 1 = 3\n",
    "let say Std as : 1  \n",
    "     \n",
    "    so in this particuler case(Test_data) we specifically apply \"transform\"\n",
    "    if we use \"fit\" with respect \"Test_data\" my \"Standardizations\" \n",
    "    mean(\"μ\") and Standardiviation(\"σ\") will change , so dotn use \"fit\"\n",
    "    with respect to \"Test_data\"\n",
    "        \n",
    "    \n",
    "for the test dataset\n",
    "\n",
    "\n",
    "wher in we are specifically using eucleadian distance \n",
    "like 1, \"K means clustering\"\n",
    "     2, \"KNN\"\n",
    "    \n",
    "    if you have Gradient decent curv and \"Eucleadian distance\"\n",
    "    that point of a time you can use \"feature scalling\"\n",
    "    \n",
    "when should we not apply feature scalling  ?\n",
    "Ans :=\n",
    "    some of the algorithem like ensimble technics here u dont \n",
    "    use \"feature scaling\" 1. Desessiontree 2, Xg_boost 3, random forest\n",
    "    \n",
    "    \n",
    "How voting will done in case of Classification ?\n",
    "\n",
    "Ans:-\n",
    "    \"voting\" in \"Classification problem\" is done based on\n",
    "    'Majority of  Votes'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d0ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9dfa9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c242272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

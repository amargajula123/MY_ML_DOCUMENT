{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420cdefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "what is ML ? \"ITUTIONS\"(చిట్కాలు)\n",
    "\n",
    "Ans:=\n",
    "    a \"algorithem\" that has an ability to learn from its \"past\"\n",
    "    \"experience\"\n",
    "\n",
    "types of ML ?\n",
    "Ans:=\n",
    "    1.Superwised MACHINE LEARNING\n",
    "    2.UnSuperwised MACHINE LEARNING  \n",
    "    \n",
    "    link:https://www.youtube.com/watch?v=VAHoryyJPaA\n",
    "            \n",
    "    *.Reinsforcement MACHINE LEARNING.\n",
    "\n",
    "@IMP {IQ}\n",
    "\n",
    "how do you select an \"Algorithem\"for your \"ML\" process ?\n",
    "\n",
    "Ans:=\n",
    "    i have expiremented with all the models whether its \n",
    "    \"Regression\" problem or \"classification\" problem State\n",
    "    ment i have check out throgh all the \"performance metrix\"\n",
    "    \n",
    "    \n",
    "which is your favarate ML \"Algotithem\" ?\n",
    "\n",
    "Ans:=\n",
    "     there is no such my fevorate Algorithem as such each and\n",
    "    every algorithem has this own pross and corns  i will \n",
    "    probably apply each and every algorithem for my problem\n",
    "    statement based on the performance metrix but with respect\n",
    "    to max the algorithem that i have understood completly\n",
    "    80 to 90 persent  \n",
    "\n",
    "\n",
    "@ML algorithems :=\n",
    "    Ml Algorithes are divided into 2 types \n",
    "    \n",
    "    1. Superwised ML\n",
    "    2. Un superwise ML\n",
    "\n",
    "1.Superwised ML Algoithems :=\n",
    "    in superwised ML basically we solve 2 types of problems\n",
    "    1.\"Regration\"\n",
    "    2.\"Classification\"\n",
    "\n",
    "2.UnSuperwised ML:= \n",
    "    in UnSuperwised ML  we solve 2 specific  problems\n",
    "    1.\"Clustring\"  this is with respect to \"Deep learning\" also\n",
    "    \n",
    "    \n",
    "    *.\"Dimensionality Reduction\"                                                  \n",
    "\n",
    "    \n",
    "why say this has \"Superwised ML Algoithems\" ?\n",
    "\n",
    "*.Superwised ML \n",
    "\n",
    "What is Regration :=\n",
    "    when your \"output feature\" is like \"Continues\" variable.\n",
    "    then it will be \"Regresion\" Problem statement\n",
    "    \n",
    "    \n",
    "    Ex = the dataset is called as \"House price predition\" \n",
    "    \n",
    "    the features (columns) will be like\n",
    "        \n",
    " <----------\"Independent_feaures\"--------->   \"Dependent_feature\"\n",
    "             |              |             |         |\n",
    "   ----------|--------------|-------------|---------|--------     \n",
    "num.of room  |   total_area |  location   |     house_price\n",
    "                            \n",
    "                                               \n",
    "    house price definetly heve \"continuous values\" feature have like 45.5lc\n",
    "56.5lc 60.3lc when ever we  saw this kinda problem this becomes \n",
    "a \"Regretion_Problem\"  b-coz my out feature is basically continues\n",
    "feature \n",
    "\n",
    "\n",
    "What is Classification :=\n",
    "    \n",
    "    \"Classificatipn\" can have \"binary\" class classification \n",
    "    or \"multy\" class classification\n",
    "    \n",
    "    Ex:= dataset like \n",
    "        \n",
    "no.of            no.of            no.of           oput\n",
    "play hours       sleep hours      study hour    pass/faile\n",
    "   7hr               6hr              1hr          fail\n",
    "   2hr               6hr              5hr          pass   \n",
    "\n",
    "                                   here \"dependent feature\" have 2 outputs\n",
    "                                  so this is a \"binari\" classificattion\n",
    "                                   if it has more then 2 outputs it could\n",
    "                                  be a \"multy\" class classification\n",
    "        \n",
    "whenever you have your output feature is having fix no.of \"categiries\" \n",
    "then that becomes a \"Classification_Problem\" suppose\n",
    "it just has \"two outputs\" then it becomes a \"binary_classification\"\n",
    "if it has more then 2 different \"categeries\" that is called\n",
    "\"multy class classification\"\n",
    "\n",
    "\n",
    "*.UnSuperwised ML \n",
    "\n",
    "@Clustring :=\n",
    "    let say my dataset like\n",
    "    \n",
    "    salary        Age       in this senario \"no dependent\"\n",
    "                             \"variable\"\n",
    "    \n",
    "what kinda assumtion we take from this dataset ?\n",
    "Ans:=\n",
    "clustaring is nothing but based on the dataset i will\n",
    "try to find out similar groups this groupes called as \n",
    "clustars each and everycluster will be specifing some \n",
    "information leman way we are \"grouping\"\n",
    "\n",
    "@Dimensionality Reduction :=\n",
    "    in Dimensionality Reduction suppose if we have 1000\n",
    "    feature convert this 1000 features to 100 feature \n",
    "    yes with the help of \"Dimensionality Reduction\"\n",
    "\n",
    "\n",
    "*.Superwised ML Algoithems :=   \n",
    "    \n",
    "Algorithems :\n",
    "    1.Simple Linear Regration Algorithem[\"regration problem\"]\n",
    "    2.Ridge Regration Algorithem[\"regration problem\"]\n",
    "    3.Lasso  Regration Algorithem[\"regration problem\"]\n",
    "    4.Elastic_Net Regration Algorithem[\"regration problem\"](comb of ridg & lasso)\n",
    "    5.Logistic Regration Algorithem [\"Classification problem\"]\n",
    "    \n",
    "    6.Naive Bayes Algorithem [\"classification Algorithem\"]\n",
    "      (NLP)->Natural Language Processing\n",
    "        \n",
    "    7.K-Nearest Neighbors (KNN)(solve both \"Classification\" and \"regression\")\n",
    "    \n",
    "  Ones you complete all upper Algorithem then you go with\n",
    "  below Algorithems \n",
    "    \n",
    "\n",
    "       1. Decsion_Tree\n",
    "       2. Random_Forest\n",
    "       3. Ada_Boost\n",
    "       4. Gradient_Boost \n",
    "       5. XG_Boost  --->  this all algorithem which can solve\n",
    "                          both \"classification\" and \"regration\"\n",
    "                          problems \n",
    "###########################################  \n",
    "\n",
    "1.{ Simple Linear Regration Algorithem }:=\n",
    "    \n",
    "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ \n",
    "Note:=\n",
    "    if my dataset have only \"One_input_feature\" than it becomes\n",
    "    \"Simple_Linear_Regression\" if i have \"multyple input features\" than\n",
    "    it becomes \"Multyple_Linear_Regression\"\n",
    "    \n",
    "    Ex dataset having 2 features -->   Height , weight \n",
    "    \n",
    "    predict the \"Height\" based on  \"weight\" \n",
    "         \n",
    "                \"Height\"\n",
    "                Y-axis\n",
    "35:19            |\n",
    "{gk}             |\n",
    "                 |\n",
    "                 | \n",
    "                 |\n",
    "                 |---------------->X-axis \"weight\"\n",
    "\n",
    "  \n",
    " in \"Linear_Regression\" we will do with the help of \"train_dataset\"\n",
    "we \"train\" a model / or give \"train_dataset\" to a model, that model is\n",
    "nothing but kind of \"hypothesis testing\", then latter on we need to give new\n",
    "\"weight\" and basesd on that it gives the o/p as new \"Height\",\n",
    "\n",
    "then with the help of \"performance matrix\" \n",
    "\n",
    "we try to verify whether this model is porforming well are not\n",
    "\n",
    "now inshot we do in \"linear regression\"  we try to find out a \n",
    "\"best fit line\" which hepls us to do the \"prediction\" here\n",
    "y axis is a linear function of x\n",
    "\n",
    "   NOTE : what inferential statistics \n",
    "        in \"hypothesis testing\" we do some 'statistical analasys' based on \n",
    "        \"sample of data\" and  we come up with \"population data\"\n",
    "        \n",
    "        so when we \"train_dataset\" or give it to a \"Model\" it is just like\n",
    "        that servig for \"entire population\"\n",
    "        \n",
    "\n",
    "Ex:= dataset id -->  weight            height\n",
    "    \n",
    "                         Train dataset\n",
    "                               |\n",
    "                               | \n",
    "                             Model\n",
    "                               |\n",
    "                               |\n",
    "  \"new weight\" ------->Hypothesis_testing----->\"predict and-->height\"\n",
    " \n",
    "    \n",
    "what this hypothesis all about ?\n",
    "    \n",
    "Ans  := this \"hypothesis\" in the case of \"Simple_Linear_Regration\" \n",
    "        is that we just need to create a \"Best Fit Line\"\n",
    "                \n",
    "how this best fit line given us ? \n",
    "ANS :=\n",
    "    by different different equations this \"best fit line\" give us \n",
    "    per suppose one equation be like \" Y = Mx + C \"\n",
    "    \n",
    "    with respect to \"hypothesis\" i write this equation like below\n",
    "     \n",
    "    [ hθ(x)=θ0 + θ1x ]--->(Equation of a \"straight line\")\n",
    "    \n",
    "   (:. θ0 = \"Intercept\" )\n",
    "\n",
    "\n",
    "          {gk} y-axis \n",
    "                ^\n",
    "                |\n",
    "                |\n",
    "                | \n",
    "              --*----------> x-axis\n",
    "               0|\n",
    "                \n",
    "         \"Intercept\" means  when X=0 then obviusly need to Y=0\n",
    " \n",
    "  \"Intercept\" means when my \"x\"= 0  where is this line\n",
    "        meting in the \"y\" axis if it pass it throgh the \n",
    "        \"origin\" then θ0 = 0\n",
    "         \n",
    "   (:. θ1 = \"Coefficent\" or \"Slope\" )\n",
    "\n",
    "                         axis\n",
    "                         y\n",
    "                         |     /\n",
    "                         |    /\n",
    "                         |   /|\n",
    "         {gk}            |  / | ---> 1 unit movemet \n",
    "                         | /__|\n",
    "                         |/  \n",
    "                         |--|--|-|--x-axis\n",
    "                            --> unit movement\n",
    "                        \n",
    "\"θ1\" or \"β1\" says that with respect to the \"unit movment\" in the \"x_axis\"what\n",
    "is the movement with respect to \"y_axis\" that movement\n",
    "        is basically shows \"Slope\"\n",
    "        \n",
    "Note :-\n",
    "    by using \"pythogores therom\" u find out the \"slop\" also \n",
    "    (x2-x1)(y2-y1) also we can calculate the \"slop\"   \n",
    "        \n",
    "        \n",
    "        \n",
    "\"problem statement \"\n",
    "        \n",
    "we need to keep on changing  \"θ0 and θ1\" values to find out\n",
    "\"Best fit line\"\n",
    "        \n",
    "let say on \"best fit line\" we having \"predictect poits\" and near to that we \n",
    "having \"real poit\". if i calculate \"sumation\" of all this \"predicted\" and\n",
    "\"real\" poits i come up with difference. this difference is called \"Error\",\n",
    "which ever giving me the \"minimal\" or \"less\" that should be treated as \n",
    "\"best fit line\" , it shoud be \"minimal\" or \"less\"\n",
    "        \n",
    "        \n",
    "Aim of the  simple linear regretion :=\n",
    "    \n",
    "    \n",
    "   40:58 \n",
    "    {gk}\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "if i have 10 lines  if i find out the \"sumation\" of the \"Error\"(difference)\n",
    "whichever line has the less 'Error'(difference) we will take/concider\n",
    "that has a \"Best Fit Line\" \n",
    "    \n",
    "\n",
    "@Multiple best fit lines :=\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    {gk}\n",
    "    \n",
    "    suppose i have a dataset its not like that if your creating multyple \"lines\"\n",
    "    to for knowing the \"best fit line\" and doing which ever \"Error\"(difference) \n",
    "    is less and select that for \"best fit line \" exactly its not a good approach,\n",
    "    \n",
    "    \n",
    "    just with one \"line\" i do the movement/optimization and find out the\n",
    "    \"best fit line\",\n",
    "    \n",
    "    \n",
    "    \n",
    "    we should \"start at one point \" and then we go towords finding the\n",
    "    \"best fit line\" for this particular perpose we use \"Cost_function\"\n",
    "    and \"Gradient Decent\"\n",
    "    \n",
    "    \n",
    "@to find out best  fit line :=\n",
    "        to find out \"best  fit line\" we use \"Cost function\"\n",
    "        \n",
    "\"hypothesis\"= hθ(x)=θ0 + θ1x    [^y - y] :.^y means on a line \"predicted point\"\n",
    "                                            y means on a line \"real point\"\n",
    "                                \"predicted point\" - \"real point\"= defference comes\n",
    "            \n",
    "            \n",
    "NOTE:=           \n",
    "    if findout the \"distance\" of \"predicted _point\" and\n",
    "    \"real_point\" for that equation is = (hθ(xi) - yi)²\n",
    "    \n",
    "                             [:.hθ(xi) = predicted point{^y}]\n",
    "                           \n",
    "\n",
    "   \"mean_squred Erorr\" formula\n",
    "            \n",
    "                                 1     m \n",
    "\"Cost function\"--> J(θ0 , θ1) = -----  ∑ (hθ(xi) - yi)² [:. hθ(x)  = θ0 + θ1x]\n",
    "                                 2m   i=1               [:. hθ(xi) = ^y      ]\n",
    "    \n",
    "[:.this \"Cost_function\" is also called as \"Mean_squred_Erorr\" ]\n",
    "    \n",
    "what is this \"Mean_squred_Erorr\"  'Cost_function' ?\n",
    "\n",
    "we are just trying to find out the difference b/w \"predicted point\"(hθ(xi))\n",
    "and 'real point'(yi) this \"diference\" is called as 'Error'\n",
    "    \n",
    "    :. 1/2 is for the \"derivation simplycity\" of max calculations\n",
    "    \n",
    "    :. (hθ(xi) - yi)² ---> this equation is for we get \"Error\"(difference)\n",
    "                           we are \"squring\" it  becoz to \"change possitive value\"\n",
    "        \n",
    "    :. m --> the total no.of \"data points\" that are available, by this i \n",
    "            will be getting \"mean\" / \"Avarage\" of all datapoint\n",
    "    \n",
    "[this \"cost_function\" is called as \"mean_squred Erorr\" Equation]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "What we need to sovle := \n",
    "    we minimize/Reduse the \"cost_function\" so that we get \"Best fit line\"\n",
    "    \n",
    "                     1    m \n",
    "      J(θ0 , θ1)=  -----  ∑ (hθ(xi) - yi)²\n",
    "                    2m   i=1\n",
    "        \n",
    "by the \"changing the value\" of 'θ0' and 'θ1' we can \"minimize\"/\"reduce\"\n",
    "the \"Cost_function\"\n",
    "        \n",
    "     this is our final goal\n",
    "        \n",
    "        \n",
    "  let say      \n",
    "  hypothesis --> hθ(x) = θ0 + θ1x    \n",
    "    \n",
    "    \n",
    "    if θ0 = 0 mean my \"best fit line\" passes though the \"origin\"\n",
    "              so  hθ(x) = 0 + θ1x\n",
    "                  hθ(x) = θ1x\n",
    "            \n",
    "             y-axis \n",
    "                ^\n",
    "                |  /\n",
    "                | /\n",
    "                |/ \n",
    "              --*----------> x-axis\n",
    "               0|\n",
    "                \n",
    "                  \"best fit line\" = hθ(x)= θ1x\n",
    "                    \n",
    "                    \n",
    "    lets say  my \"dataset point\" will be looks like  \n",
    "    \n",
    "             y-axis \n",
    "                ^\n",
    "                |\n",
    "              3-|-            *        i have data poind like(1,1)(2,2)(3,3)\n",
    "                |                      'y' is my dependent/output featuer\n",
    "              2-|-        *            'x' is independent/ input feature\n",
    "                |                      this is my \"trainig datapoints\"\n",
    "              1-|-   *                       \n",
    "                |                            \n",
    "             ---|----|----|----|----> x-axis\n",
    "               0|    1    2    3 \n",
    "                \n",
    "                                    θ1 = 1 my \"best fit line\" looks\n",
    "                                   like this\n",
    "        here θ0 = 0  b-coz my \"best fit line\"\n",
    "        'passes through the origin'. so my 'hypothesis'\n",
    "         will be --> [ hθ(x)= θ1x ]\n",
    "                    \n",
    "        how we are chang the \"Best fit line\" ?\n",
    "        \n",
    "         ans := by changing the \"θ1\" value we can not change \"θ0\" value\n",
    "                b-coz its 0 when \"best fit line\" passes through the origin\n",
    "        \n",
    "     \n",
    "             \n",
    "                              hθ(x) = θ1x  and x = 1,2,3 data points \n",
    "if θ1 = 1    if \"x_axis = 1\" so hθ(x) = 1(1) = 1\n",
    "             if \"x_axis = 2\" so hθ(x) = 1(2) = 2\n",
    "             if \"x_axis = 3\" so hθ(x) = 1(3) = 3 this numbers to pointing  \n",
    "                                               predicted/dependent feature\n",
    "                                               data points for bets fit line \n",
    "        :.θ0 = 0\n",
    "            \n",
    "            \n",
    "                  1    m\n",
    "        J(θ1) = -----  ∑ (hθ(xi) - yi)²\n",
    "                 2m   i=1\n",
    "            \n",
    "           [ m = \"best fit lines total no.of data points\" 3 ]\n",
    "            \n",
    "            \n",
    "                                      hθ(x) = θ1x\n",
    "                \n",
    "                let say  if with respect to 'x_axis = 1' and  θ1 = 1\n",
    "                     \n",
    "                        hθ(x) = θ1x => 1(1) = 1 uotput=1\n",
    "                    \n",
    "                                (output - x_axis)² == (^y-y)²\n",
    "                        \n",
    "                                (1-1)² = 0 \n",
    "                                similarly with 2 , 3 x-axis & θ1 = 1\n",
    "            \n",
    "                      1    3\n",
    "            J(θ1) = -----  ∑ [(1-1)² + (2-2)² + (3-3)²]\n",
    "                     2(3) i=1\n",
    "                \n",
    "            J(θ1) = 0\n",
    "                \n",
    "                \n",
    "    J(θ1) = 0 means Predicted_point - real_point = 0 Difference\n",
    "            means it a \"Best fit line\". ofcouse its \"minimal\"\n",
    "            \n",
    "            \n",
    "        so\n",
    "             J(θ1)--->Cost_fun=0\n",
    "                ^               \n",
    "                |                  \n",
    "            1.5-|--                           \n",
    "                |                   \n",
    "              1-|- \n",
    "                |                     \n",
    "           J(θ1)|                          \n",
    "             ---*----|----*----|---> (θ1)=1\n",
    "               0|   0.5   1   1.5   \n",
    "                \n",
    "            \n",
    "   cost_function is \"0\" over here that means the difference \n",
    "B/W \"predicted\" and \"real point\" is \"Zero\"\n",
    "            \n",
    "            y-axis \n",
    "                ^\n",
    "              3-|-                            * if θ1 = 1 my \"Best_fit_line\"\n",
    "                |                             |  look like this\n",
    "            2.5-|-                            |        \n",
    "                |                             |diff (1.5-3)       \n",
    "              2-|-                  *         |\n",
    "                |                   |         |\n",
    "            1.5-|--                 |(1-2)²   ● if θ1 = 0.5 my \"Best_fit_line\"\n",
    "                |                   |            look like this\n",
    "              1-|-        *         ●\n",
    "                |         |(0.5-1)² diff its called \"Error_Rate\"\n",
    "            0.5-|-        ●\n",
    "                |                          \n",
    "             ---*----|----|----|----|----|----|----> x-axis\n",
    "               0|   0.5   1   1.5   2   2.5   3      \n",
    "                    \n",
    "                                          and x = 1,2,3 data points\n",
    "if θ1 =0.5  if \"x_axis = 1\" so hθ1(x) = 0.5(1) = 0.5\n",
    "            if \"x_axis = 2\" so hθ1(x) = 0.5(2) = 1\n",
    "            if \"x_axis = 3\" so hθ1(x) = 0.5(3) = 1.5\n",
    "                                                 \n",
    "                       1                              \n",
    "            J(0.5) = -----  [(0.5-1)² + (1-2)² + (1.5-3)²]                                                     \n",
    "                       2(3)  [m=total no.of points]\n",
    "                \n",
    "                \n",
    "             J(θ1) = 0.5833\n",
    "            \n",
    "            \n",
    "            so\n",
    "            J(θ1) = 0.5833\n",
    "                ^               \n",
    "                |                  \n",
    "            1.5-|--                           \n",
    "                |                   \n",
    "              1-|- \n",
    "                |\n",
    "                |    *         \n",
    "            0.5-|-          \n",
    "                |                          \n",
    "             ---*----|----|----|---> (θ1)0.5\n",
    "               0|   0.5   1   1.5      \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "so finally we calculate the \"Error_rate\" with the difference B/W\n",
    "the points we calculated like (θ1 = 1) and (θ1 = 0.5) \n",
    "                                                 \n",
    "                                                 \n",
    "                                                \n",
    "                                     and x = 1,2,3 data points             \n",
    "if θ1 = 0     \"x_axis = 1\" so hθ1(x) = 0(1) = 0\n",
    "             \"x_axis = 2\" so hθ1(x)  = 0(2) = 0\n",
    "             \"x_axis = 3\" so hθ1(x)  = 0(3) = 0\n",
    "        \n",
    "                y\n",
    "              2-|- \n",
    "                |        \n",
    "              1-|-        \n",
    "                |                          \n",
    "             ---*----*----*----*---> x\n",
    "               0|    1    2    3   \n",
    "                                                  \n",
    "                     1                                 \n",
    "           J(θ1)  = --- [(0 - 1)² + (0 - 2)² + (0 - 3)²]  1+4+9 = 14/6\n",
    "                     6 \n",
    "            \n",
    "            J(θ1) = 2.3\n",
    "            \n",
    "            so\n",
    "             J(θ1) = 2.3 \n",
    "                ^\n",
    "              3-|-\n",
    "                *\n",
    "              2-|- \n",
    "                |         \n",
    "              1-|-        \n",
    "                |                          \n",
    "             ---*----|----|----|---> (θ1)= 0\n",
    "               0|   0.5   1   1.5   \n",
    "                                                      \n",
    "if i combine this all  J(θ1) = 0  J(θ1) = 0.5833  J(θ1) = 2.3  points its looks\n",
    "like \"u\" shape model  this is basically a \"Porabola\" or we can say \n",
    "\"Gradient_Decent\" Curv\n",
    "        \n",
    "        \n",
    "             J(θ1) = 0\n",
    "             J(θ1) = 0.5833\n",
    "             J(θ1) = 2.3 \n",
    "                ^\n",
    "              3-|-                        \n",
    "                |                         \n",
    "            2.5-|-                          \n",
    "                | \n",
    "                *\n",
    "              2-|-        \n",
    "                |      \n",
    "            1.5-|--                  \n",
    "                |                \n",
    "              1-|-  \n",
    "                |\n",
    "                |    *      \n",
    "            0.5-|-       \n",
    "                |                          \n",
    "             ---*----|----*----|----|----|----|----> (θ1) = 1\n",
    "               0|   0.5   1   1.5   2   2.5   3      (θ1) = 0.5\n",
    "                          |                          (θ1) = 0\n",
    "                          |\n",
    "                         here it having \"One_Global_Minima\" point \n",
    "                    and \"Slop\" will be very less or apractumatly = 0\n",
    "                                                      \n",
    "why we specifically using \"Mean_Squared_Erorr\" ?\n",
    "                                                     \n",
    "Ans :=\n",
    "    the resion why we are using \"Mean Square Erorr\" is b-coz it\n",
    "    definetly form a \"quadratic equation\" , and it has only\n",
    "    \"One_Global_Minima\" ,\"not local minima\"\n",
    "    \n",
    "    the  \"Quadratic_Equation\" it usually form \"Curv\" like \"Parabola\"\n",
    "     or \"Gradient_Decent\" Curv\n",
    "    \n",
    "        ax² + bx + c =0  \n",
    "                           1    m\n",
    "                         -----  ∑ (^y-y)²  ==> \"quadratic equation\"\n",
    "                           2m  i=1 \n",
    "                    \n",
    "    this ax² + bx + c =0 this usually forms a \"Parabola\"  or \n",
    "    \"Gradient_Decent\" Curv\n",
    "                                                     \n",
    "which is the best point in \"quadratic equation\" or \"Mean Square Erorr\" ?\n",
    "                                                     \n",
    "Ans :=\n",
    "   wherever your \"Erorr\"(difference) is \"minimal\" or apractumatly = 0\n",
    "   that point is specifically called as \"Global Minima\"                      \n",
    "                                                      \n",
    " but here we took   θ1 = 1  θ1 = 0.5  θ1 = 0  why we are taking like\n",
    "this can we come up with a apporoch where in once  \"θ1\" values initia\n",
    "lizes it shoud get automatically \"subtracted\" are \"added\" based on this\n",
    "\"gradient desent\" to reach the \"global minima\".\n",
    "\n",
    "So this \"Gradient Desent algorithem\" uses somthin called as \n",
    "\"Convergence Algorithem\".\n",
    "\n",
    "@Gradient Desent algorithem uses Convergence Algorithem:=\n",
    "   Ans :=\n",
    "    \"convergence algrm\" says repeat until \"Convergence\" its just\n",
    "    a SUDO Alrgm\n",
    "    \n",
    "             J(θ1) = 0      }  \n",
    "             J(θ1) = 0.5833 }-- value we get throug (θ1) so (θnew) just say\n",
    "             J(θ1) = 2.3    }\n",
    "                \n",
    "                \n",
    "                    (θ1) = 1   }\n",
    "                    (θ1) = 0.5 }--> just concider this value for Updation \"θ\" \n",
    "                    (θ1) = 0   } \n",
    "                    here we saying \"θnew = ~ θold\",\"θnew\" is oprocumatly\n",
    "                                                     equal to \"θold\"\n",
    "    \n",
    "             (θnew)\n",
    "              j(θ1) \n",
    "                ^\n",
    "              3-|-                        \n",
    "                |                         \n",
    "            2.5-|-                          \n",
    "                | \n",
    "                *\n",
    "              2-|-        \n",
    "                |      \n",
    "            1.5-|-⚫--->we can say this point as \"loss_fun\"points also                                   \n",
    "                |  |              \n",
    "              1-|- | \n",
    "                |  |  \n",
    "                |  |--*      \n",
    "            0.5-|-       \n",
    "                | --->                        \n",
    "             ---*-•---|----*-----|----|----|----|----> (θ1) (θold) \n",
    "               0|    0.5   |1   1.5   2   2.5   3     \n",
    "                           |\n",
    "                          \"Global Minima point\"\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "lets say i training our model i got one point over ⚫ here with \n",
    "respect to \"θ1\" to that same point my \"Coeffiecnt\" will be • here.\n",
    "now our \"main aim\" is to come/go towords the \"Global Minima point\"\n",
    "so we need to Update the \"θ\" value\n",
    "        \n",
    "             {  \n",
    "                           ∂(θJ)\n",
    "            θJ = θJ - α -----------  ==>\"coefficient\"/\"Slope\" updation  \n",
    "                           ∂(θJ)       formula\n",
    "             }\n",
    "            \n",
    "            I CAN WRITE THIS AS \n",
    "        \n",
    "    now how this \"θ\" Updation happens ?\n",
    "    \n",
    "                                              \n",
    "           {  \n",
    "                             ∂(J(θold))\n",
    "            θnew = θold - α -----------  ==>\"Coefficient\"/\"Slope\" updation  \n",
    "                               ∂(θold)       formula\n",
    "           }   \n",
    "                                                 \n",
    "    α ---> \"Learning_Rate\" will helps us to deterine the\n",
    "           \"Speed of Convergence\"\n",
    "        \n",
    "                                    \"Partial Derivative\"                   \n",
    "               ∂(J(θold))                                      \n",
    "              -------------  ==> this \"derivative\" for calculate the \"Slop\"  \n",
    "                  ∂θold       when we say \"derivative\" means we calculating\n",
    "                              the \"Slop\" at a \"specific point\".\n",
    "                    \n",
    "how to calculate the \"Slop\" ?\n",
    "Ans:-\n",
    "  ill create one 'Tangent line' and see whethr it is \"+ve\" slop or \n",
    "  \"-ve\" Slop\n",
    "    \n",
    "how to finde whether its a +ve or -ve Slop ?\n",
    "    after creating 'Tangent line' we need to see is from right hand\n",
    "    side it folls down or it goes up. if foll down means \"-ve_Slope\" \n",
    "    is goes up means \"+ve_Slop\"\n",
    "                                                 \n",
    "    [:. if you have -ve \"Slop\" your value will  be \"-ve value\" ]\n",
    "    \n",
    "           θnew = ~ θold - α( -ve value )                                                \n",
    "           θnew =~ θold + ve value\n",
    "\n",
    "            if i add this  2 val \"θold + ve value\" definatle \"θnew\"\n",
    "            become \"big value\" we actually need this to reach the \n",
    "            \"Global Minima point\"\n",
    "    \n",
    "        So θnew >> θold  :. here definatly \"θnew\" is grater then the \"θold\"  \n",
    "        \n",
    "        lest say\n",
    "        \n",
    "    (θnew)\n",
    "              j(θ1) \n",
    "                                        \n",
    "            2.5-|-                          \n",
    "                | \n",
    "                *\n",
    "              2-|-        \n",
    "                |      \n",
    "            1.5-|-                 ⚫                                  \n",
    "                |                   |\n",
    "              1-|-                  |\n",
    "                |                ---|\n",
    "                |     *      \n",
    "            0.5-|-       \n",
    "                | --->       <-----       \n",
    "             ---*----|-----*-----|--•-|----|----> (θ1) (θold) \n",
    "               0|    0.5   |1   1.5   2   2.5       \n",
    "                           |\n",
    "                        \"Global Minima point\"\n",
    "                        \n",
    " \n",
    "Now again with respespect \"θ1\" i got \"loss\"/\"cost_fun\" over ⚫ to this \n",
    "point my \"Coefcient\"(θ1) will be here • . in this case i decrease the \n",
    "\"θ\" value\n",
    "            \n",
    "so after creting \"Tangent line\" on right and see the \"slop\" whether \n",
    "it is a \"+ve/-ve\" ,here \"+ve Slop\". here we need to reduce the \"θ\" \n",
    "to reach the  \"Global Minima point\"\n",
    "how means\n",
    "                                                      \n",
    "    [:. if you have +ve \"Slop\" your value will  be \"+ve value\" ] \n",
    "    \n",
    "           θnew =~ θold - α( +ve value )                                                \n",
    "           θnew =~ θold - ve value                                             \n",
    "           θnew << θold\n",
    "        \n",
    "when \"θ\" movement will stop moving ?\n",
    "Ans:-\n",
    "    when it will reach \"Global Minima point\" it stops\n",
    "        \n",
    "α --->\"Learning_Rate\" will helps us to deterine the \"speed of Convergence\"\n",
    "    \n",
    "      ex := if i take α = 1 ,θold = 1,\n",
    "             +ve value = 1\n",
    "            \n",
    "            θnew =1 - 1( -1 ) is -ve slop(-1)\n",
    "            θnew = 1+1=2\n",
    "            \n",
    "            if α = 4\n",
    "            θnew =1 - 4( -1 ) = 5 see by changing \"α\"(Learning_Rate) \n",
    "                              it speedly goes towords \"Global Minima point\"\n",
    "                \n",
    "                So \"α\" it determines  \"speed of convergence\"\n",
    "                \n",
    "    \n",
    "NOTE := \n",
    "    \"Gradient_Decent\" or \"parabola\" which is called as \"Mean Square Erorr\"\n",
    "    \n",
    "why we ned to reach the \"Global Minima point\", when we know we get our\n",
    "\"Global Minima point\" at  θ = 1  ?\n",
    "\n",
    "\n",
    "what will the \"equation\" becom when i have\n",
    "  \"x1\"  \"x2\" \"x3\"  \"x4\" \"y\" like features\n",
    "  \n",
    "my equation bcomes like\n",
    "\n",
    "hθ(xi) = θ1x1 + θ2x2 + θ3x3 + θ4x4 + θ0  ---> this is caled as\n",
    "                              \"Multy_Linear_Regretion\"\n",
    "    \n",
    "V.V.IMP     \n",
    "**IMP \"gradient Decent\" [\"MSE\"] Advantages :=\n",
    "      1.There is \"one global minima\"  {iq quation}\n",
    "      2.whenever we have \"Quadritic equation\" it is \"differetiable\"    \n",
    "                                                     \n",
    "      Disadvantage :=\n",
    "      1.it is not robust to \"Outliers\"and in case of \"Mean Square Erorr\"\n",
    "        it \"Penalizes\" the \"Erorr\"  (^y-y)² we are squring the \"Error\"(diff)\n",
    "        so it may become \"huze\" impact on to fit the 'Best fit line' means\n",
    "        \"movement\" is high\n",
    "        \n",
    "           \n",
    "        Outliers\n",
    "        ^  |\n",
    "        | ** /\n",
    "        |  */   * *                                      \n",
    "        |  /  **  *\n",
    "        | /   * *\n",
    "       -|/----------\n",
    "    \n",
    "if there is \"Outliers\" in \"MSE\" \" mean square erorr\" :=\n",
    "    \n",
    "   we use another type of \"Gradient decent\" that is \n",
    "   \"MEAN ABSOLUTE ERORR\" .\n",
    "    \n",
    "                 1    m  \n",
    "  J(θ0 , θ1) = -----  ∑ |^y- y|    [ :. ^y = hθ(xi) ]                                             \n",
    "                 m   i=1    \n",
    "    \n",
    "                                                 \n",
    "        | * *  /\n",
    "        |* *  /*                                    \n",
    "        | *  /**    if i use \"Mean Absolute Error\" \n",
    "        |   /* *     my \"Best fit line\" looks like this                                 \n",
    "        |  /**  *    b-coz we are \"not squaring\" the \"Error\"(difference)\n",
    "        | /* *       when we get \"Absolute value\" we dont take \"-ve value\"\n",
    "       -|/----------                                            \n",
    "           here there is not a mager movement of \"best fit line\"  \n",
    "        \n",
    "        \n",
    "\"MEAN ABSOLUTE ERORR\"  will convert this \"Gradient_Decent\"  into\n",
    "or create curv like\n",
    "\n",
    "                            |     \n",
    "                   *        |       *\n",
    "                    *       |      *     this i not say \"Gradient_Decent\"\n",
    "                     *      |     *    we use \"Sub_Gradient_Decent\" concept\n",
    "                        *   |  *\n",
    "             ---------------*-------------- \n",
    "                            |\n",
    "                            |\n",
    "what \"Sub_Gradient_Decent\" means  ?\n",
    "    we devide this into \"parts\" and we try to find the \"Slop\"\n",
    "    why \"Slop\" b-coz with respect different 'Plots', \"Slop\" may change\n",
    "                             \n",
    " --------------------------------------------------------------------       \n",
    "        \n",
    "          \n",
    "                                                 \n",
    "                                                 \n",
    "                                                 \n",
    "    the slop here is 0 in this case will be stuck in \n",
    "    \"local minima\"                                              \n",
    "{IQ} do you see \"local minima\" in regresion ?\n",
    "                                                 \n",
    "Ans:=\n",
    "    the cost function that we use  will defeinatly not\n",
    "    give local minima  in deep learnig we solv this local\n",
    "    minima like ANN like optimizers                                             \n",
    "                                                 \n",
    "                                                 \n",
    "                                                 \n",
    "     \n",
    "                                                 \n",
    "                                                 \n",
    "                                                     \n",
    "###################################################################333\n",
    "\n",
    "What are the Performence metrix we use with respect to \"linear\" \n",
    "Regression ?\n",
    "\n",
    "***Performence metrix :=\n",
    "                                    \n",
    "\"R²\" and \"Adjusted_R²\":-\n",
    "    when ever we use this \"R²\" and \"Adjusted_R²\" , \"performance metrix\" \n",
    "    means how good our  \"Best fit line\" is   \n",
    "        \n",
    "lets say \"data points\" looks like below\n",
    "\n",
    "        Y\n",
    "        ^          *\n",
    "        |         * *\n",
    "        |       ** *\n",
    "  \"ȳ\"---|------* *------- this is my \"Avarage\" value of \"Y\" let say  \n",
    "        |     * *\n",
    "        |   ***  \n",
    "        | ** \n",
    "       -|------------->X\n",
    "                                    \n",
    "                                   \n",
    "                                    \n",
    "             Ss_Res            [:.Ss_Res   = \"some_of_resideal\"]             \n",
    "   R² = 1 - ---------          [:.Ss_total = \"some_of_total\"   ]                       \n",
    "             Ss_total\n",
    "                        \n",
    "               some_of_resideal = ∑(yi - y^)²\n",
    "               some_of_total    = ∑(yi - ȳ)²    [:. ȳ =  \"Mean\"]\n",
    "                                                 \n",
    "(yi - y^)² = \"Predicted_point\" - \"real_point\" = \"Error\"(difference)\n",
    "(yi - ȳ)²  = \"each and every point\" - \"ȳ the mean\" = difference we are calculating\n",
    "\n",
    "                    \n",
    "     ∑(yi - y^)²   -->\"difference_less\" value come, why less_value  \n",
    "                       b-coz we chacking with whichever data point\n",
    " 1 - ------------      that is near to \"Best_fit_line\" only concider that point\n",
    "    \n",
    "     ∑(yi - ȳ)²    -->\"difference_high\" value come, b-coz we check\n",
    "                       with \"each ond every point\"\n",
    "                                                 \n",
    "                                                 \n",
    "                                                 \n",
    "            less_value    \n",
    "            -----------   = \"1 - small_number\" =  \"higher number\"\n",
    "             high_value                                         \n",
    "                                                                                              \n",
    "    \n",
    "Note  := what ever value we get with respect to \"perfommance matrix\"\n",
    "         it will be B/W  [\"0 to 1 \"] \n",
    "       \n",
    "    Note :=\n",
    "        \n",
    "        if i get near to 1 then \"best fit line\" is \"good prediction\"\n",
    "        if i get near to 0 then \"best fit line\" is \"not that good prediction\"\n",
    "        means 'Error'(difference) is More/high\n",
    "        \n",
    "        \n",
    " IMP \n",
    "\n",
    "Can i get  \"R²\" is nagative value ?\n",
    "ans :=\n",
    "    our \"best fit line\" is  worse than our specific \"mean\"(\"ȳ\")/\"Average\"\n",
    "    line then i may get a \"nagative value\", if i am getting near to one \n",
    "    i am getting \"best fit line\"                                               \n",
    "                                    \n",
    "\n",
    "\"Adjusted_R²\" :=\n",
    "                                                      \n",
    "      lets say i have House pricing dataset  \n",
    "                                    \n",
    "   No.of     total        opt\n",
    "  rooms      size         Price                     \n",
    "                                 \n",
    "        \n",
    "   let say i get  \"R²\" is 89% or 0.89\n",
    "                                    \n",
    "# adding some new feature                                    \n",
    "   No.of     total   location      opt\n",
    "  rooms      size                   Price\n",
    "   \n",
    "    if i add \"location\" feature then obviously\n",
    "    otput price value will increase\n",
    "                                    \n",
    "                         here i get    \"R²\" is 0.95 \n",
    "                                    \n",
    "# adding some new feature                                     \n",
    "    No.of     total   location  gender     opt\n",
    "  rooms      size                          Price \n",
    "\n",
    "if i add one more feature like \"gender\" is it impact on price obviously \"NO\"\n",
    "but if we concider \"R²\" the value will increase by a \"smaller nummber\"\n",
    "                                    \n",
    "    here i get \"R²\" is 0.96 but this should not happen !\n",
    "    so that is the resion we have \"Adjusted_R²\".\n",
    "    \n",
    "let say inial  \"R²\" = 0.89 in case \"Adjusted_R²\" = 0.87 let say\n",
    "then if we add a \"new feature\" that is \"very much Correlated\" to price\n",
    "\"Adjusted_R²\" may increase. but it may increase by a \"Margin\". like\n",
    "and \"Adjusted_R²\"  this is bassically to reduse \"Over_fitting\".\n",
    "\n",
    "if incase of \"Adjusted_R²\" if we add a \"new feature\" which is not at all\n",
    "\"Correlated\"  \"Adjusted_R²\" will \"Pinalyze\" it and it will make it \"Decreases\"\n",
    "or \"less\" means the \"Adjusted_R²\" will \"decrese\" it.\n",
    "\n",
    "\n",
    "    \n",
    "\"Adjusted_R²\" how it decrease the value ? \n",
    "                                                 \n",
    "\n",
    "                                   \n",
    "\"Adjusted_R²\" is 0.87  \n",
    "                                                 \n",
    "                     (1 - R²)(N - 1)               \n",
    "    Adjusted_R² = 1 - -----------------  [:.p = features or no.of predictores ]\n",
    "                       N - P - 1         [:.N = no.of datapoits ]\n",
    "                                                      \n",
    "lets say if my p = 2 i got  R² = 90%  Adjested_R² = 86%\n",
    "    \n",
    "   let say if i add one new feature that is not all \"Correlates\"\n",
    "\n",
    "              p = 3 R² = 91%  Adjested_R² = 82%  \n",
    "    \n",
    "\"R²\" will increase just by 1% or 2% if this is not \"Correlates\" with\n",
    "    new added \"feature\" but  \"R²\" definatly increase\n",
    "   \n",
    "\n",
    " why \"Adjusted_R²\" will decrease ?\n",
    "    \n",
    "                      (1 - R²)(N - 1)   let say  p = 2 i got  \"R²\" = 90%            \n",
    "    Adjusted_R² = 1 - ----------------- if  p = 2 & N = 100 let say (100-2-1)=97\n",
    "                         N - P - 1      so 97- ((1 - R²)(N - 1))/97 the will be \n",
    "                                        \"+ve\" means this upper equation will \n",
    "                                        will increse. and \"denominater decrese\".\n",
    "                                       if we add p = 3 again a new feature again it\n",
    "                                       still decreases the \"denominater\".\n",
    "                \n",
    "                        higher\n",
    "    so  if p=3 =>  1 - -------- = 1- higher = smaller < [p=2] < [p=1]\n",
    "                        small\n",
    "        \n",
    "    So \"p\" means \"features\" right whenever \"p\" value increases which\n",
    "    is not at all \"Correlated\" it will \"Decreses\" the value\n",
    "                \n",
    "                \n",
    "    becoz of p=3 \"feature\" i get some value, this is obviously\n",
    "    \"less then\" privious value of p=2 \"feature\"\n",
    "                            \n",
    "        let say N=10 , p=2, R² = 90% so\n",
    "        \n",
    "                     (1 - 0.90)(10 - 1)              \n",
    "    Adjusted_R² = 1 - ----------------- = 0.87 so \"Adjusted_R²\" will decreses\n",
    "                        10 - 2 - 1  \n",
    "        \n",
    "if i add one more feature(p=3) then \"Adjusted_R²\"= 0.85 so \n",
    "it will still  \"decrease\"\n",
    "        \n",
    "when my \"features\"(p=1,2,3..etc) value increase \"Adjusted_R²\"\n",
    "will try it to \"decrease\"\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "         if p = 2\n",
    "            p = 3                                           \n",
    "\n",
    "    previous state is higher when p = 2 \n",
    "    \n",
    "        \n",
    "                                                 \n",
    "                  R² = 0.90/90%  p = 2  n = 100\n",
    "                                                      \n",
    "                        (1 - 0.90)(100 - 1)                              \n",
    "      Adjusted_R² =  1 - --------------------  = 1-0.102 = 0.897                                   \n",
    "                            100-2-1\n",
    "        \n",
    "        Adjusted_R²   = 0.897 < R² = 90%  so \"R²\" is obviously \"greater\"\n",
    "        \n",
    "    if p = 3 \n",
    "          \n",
    "          Adjusted_R² = 1-0.103 =  0.896 it still \"decresing\"\n",
    "        \n",
    "           if \"p\" or \"feature\" or \"predictor\" increase Adjusted_R² \n",
    "            will \"decrease\"\n",
    "     \n",
    "                                                      \n",
    "                                                      \n",
    "                  R² = 0.91  p = 3  n = 100\n",
    "                                                      \n",
    "                         (1 - 0.91)(100 - 1)                              \n",
    "     Adjusted_R² =  1 - ----------------------= 1-0.0918 = 0.908                                   \n",
    "                            100-3-1\n",
    "                     \n",
    "           so   : R² >> adjested R².\n",
    "\n",
    "with respect to \"performance matrix\"what you have seen ?\n",
    "Ans:=\n",
    "    with respect to \"performance matrix\" i have know \n",
    "    \"R²\" and  \"Adjested R²\" if there are \"more features\" that                                          \n",
    "     are highly \"Correlated\" with \"dependent/opt feature\" the\n",
    "    difference B/W \"R²\" and  \"Adjested R²\" will be higher .         \n",
    "                                                 \n",
    "Gradient decent \" RMSE \"  :=\n",
    "    RMSE is nothing but \"Root Mean Square Erorr\"\n",
    "    \n",
    "   Formula   \n",
    "                   \n",
    "                                    Σ(xi – yi)²\n",
    "                      RMSE =     √ ----------\n",
    "                                        n                                               \n",
    "                     \n",
    "        \n",
    "                                    \n",
    "Linear Regretion Assumtions :=\n",
    " 1. linear regration will perform well if there is a\n",
    "    linear Relationship with x & y.\n",
    "    \n",
    " 2. independent feature should have \"normal distribution\" \n",
    "    if 2 features have \"closly datapoints\" then its \"normal distribution\" \n",
    "    \n",
    " 3. Always take care of \"multy collinerality\"\n",
    " 4. Homoscedacity it means all the \"features\" will heve \"same Variance \"\n",
    "    like if 2 \"features\" have same \"Variance\" i can use one of those \n",
    "    \n",
    " 5. Feature Scaling require ?\n",
    "Ans := yes there are multiple features with respect different defferent\n",
    "    features it may be different of unit scale. so feature scaling is\n",
    "    required.\n",
    "        \"or\"\n",
    "    interanally \"Gradient Desent\" used. when ever \"Gradient Desent\" is\n",
    "    used in \"simple linear regression\" we want to quickly converge into\n",
    "    the \"Global minima\" so my value should be \"smaller\" so that it will\n",
    "    find out the \"derivative\" \n",
    "    \n",
    " 6. Hetroscedacity ? assignment                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4661670c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0260c694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec913391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4deb1a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((0.5-1)**2) + ((1-2)**2) + ((1.5-3)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d1e3bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5833333333333334"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.5/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebcdcff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198b6179",
   "metadata": {},
   "outputs": [],
   "source": [
    "AI vs ML vs DL vs DS\n",
    "\n",
    "\n",
    "AI application is able to do its own task without any\n",
    "human intervention\n",
    "\n",
    "Ex:= Netflix\n",
    "    if you continueosly watching comedy movies then you\n",
    "    will be recommanded with comedy movies]\n",
    "    \n",
    "    \n",
    "Machine learning sub set of AI the role ML is it provides \n",
    "Stats tools  analize the data visualize the data to do\n",
    "preditions and forecosting\n",
    "\n",
    "DL is sub set set of ML  in 1950 1960 scintist thought\n",
    "that can we make machine learn how we human being learn \n",
    "here the plane is to mimic human brain \n",
    "\n",
    "\n",
    "client Embitel Technologis in benglore\n",
    "payrole \"UJR\" solutions pvt ltd hyderabad\n",
    "curenet ctc is 3.2\n",
    "Expecting 7.5\n",
    " is it nagesible 7 \n",
    "notice peroid 2 months\n",
    "  is it nagesible yea 1 month\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb02d52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09999999999999998"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e327432b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14999999999999997"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8999999999999998/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f15dce2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8714285714285714"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-0.12857142857142853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "736f181b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18999999999999995"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-0.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2accea22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7099999999999995"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.18999999999999995*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea640c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2849999999999999"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.7099999999999995/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0762f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
